


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Coding a pixel-based DQN using TorchRL &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Reference" href="../reference/index.html" />
    <link rel="prev" title="Coding DDPG using TorchRL" href="coding_ddpg.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  main (None )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="coding_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrl_demo.html">Introduction to TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models.html">Using pretrained models</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="multi_task.html">Task-specific policy in multi-task environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_ddpg.html">Coding DDPG using TorchRL</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Coding a pixel-based DQN using TorchRL</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/knowledge_base.html">Knowledge Base</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Coding a pixel-based DQN using TorchRL</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/coding_dqn.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">tutorials/coding_dqn</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorials-coding-dqn-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="coding-a-pixel-based-dqn-using-torchrl">
<span id="sphx-glr-tutorials-coding-dqn-py"></span><h1>Coding a pixel-based DQN using TorchRL<a class="headerlink" href="#coding-a-pixel-based-dqn-using-torchrl" title="Permalink to this heading">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/vmoens">Vincent Moens</a></p>
<p>This tutorial will guide you through the steps to code DQN to solve the
CartPole task from scratch. DQN
(<a class="reference external" href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">Deep Q-Learning</a>) was
the founding work in deep reinforcement learning.
On a high level, the algorithm is quite simple: Q-learning consists in learning a table of
state-action values in such a way that, when encountering any particular state,
we know which action to pick just by searching for the action with the
highest value. This simple setting requires the actions and states to be
discrete, otherwise a lookup table cannot be built.</p>
<p>DQN uses a neural network that encodes a map from the state-action space to
a value (scalar) space, which amortizes the cost of storing and exploring all
the possible state-action combinations: if a state has not been seen in the
past, we can still pass it in conjunction with the various actions available
through our neural network and get an interpolated value for each of the
actions available.</p>
<p>We will solve the classic control problem of the cart pole. From the
Gymnasium doc from where this environment is retrieved:</p>
<div class="line-block">
<div class="line">A pole is attached by an un-actuated joint to a cart, which moves along a</div>
<div class="line">frictionless track. The pendulum is placed upright on the cart and the goal</div>
<div class="line">is to balance the pole by applying forces in the left and right direction</div>
<div class="line">on the cart.</div>
</div>
<figure class="align-default">
<img alt="Cart Pole" src="../_images/cartpole_demo.gif" />
</figure>
<p><strong>Prerequisites</strong>: We encourage you to get familiar with torchrl through the
<a class="reference external" href="https://pytorch.org/rl/tutorials/coding_ppo.html">PPO tutorial</a> first.
This tutorial is more complex and full-fleshed, but it may be .</p>
<p>In this tutorial, you will learn:</p>
<ul class="simple">
<li><p>how to build an environment in TorchRL, including transforms (e.g. data
normalization, frame concatenation, resizing and turning to grayscale)
and parallel execution. Unlike what we did in the
<a class="reference external" href="https://pytorch.org/rl/tutorials/coding_ddpg.html">DDPG tutorial</a>, we
will normalize the pixels and not the state vector.</p></li>
<li><p>how to design a QValue actor, i.e. an actor that estimates the action
values and picks up the action with the highest estimated return;</p></li>
<li><p>how to collect data from your environment efficiently and store them
in a replay buffer;</p></li>
<li><p>how to store trajectories (and not transitions) in your replay buffer),
and how to estimate returns using TD(lambda);</p></li>
<li><p>how to make a module functional and use ;</p></li>
<li><p>and finally how to evaluate your model.</p></li>
</ul>
<p>This tutorial assumes the reader is familiar with some of TorchRL
primitives, such as <a class="reference external" href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="(in tensordict vmain (0.0.2b+e22db6d ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code></a> and
<code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDictModules</span></code>, although it
should be sufficiently transparent to be understood without a deep
understanding of these classes.</p>
<p>We do not aim at giving a SOTA implementation of the algorithm, but rather
to provide a high-level illustration of TorchRL features in the context
of this algorithm.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">functorch</span> <span class="kn">import</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">tensordict</span> <span class="kn">import</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class"><span class="n">TensorDict</span></a>
<span class="kn">from</span> <span class="nn">tensordict.nn</span> <span class="kn">import</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.get_functional.html#tensordict.nn.get_functional" title="tensordict.nn.get_functional" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-function"><span class="n">get_functional</span></a>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchrl.collectors</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.html#torchrl.collectors.collectors.MultiaSyncDataCollector" title="torchrl.collectors.collectors.MultiaSyncDataCollector" class="sphx-glr-backref-module-torchrl-collectors-collectors sphx-glr-backref-type-py-class"><span class="n">MultiaSyncDataCollector</span></a>
<span class="kn">from</span> <span class="nn">torchrl.data</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.replay_buffers.storages.LazyMemmapStorage.html#torchrl.data.replay_buffers.storages.LazyMemmapStorage" title="torchrl.data.replay_buffers.storages.LazyMemmapStorage" class="sphx-glr-backref-module-torchrl-data-replay_buffers-storages sphx-glr-backref-type-py-class"><span class="n">LazyMemmapStorage</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer" title="torchrl.data.TensorDictReplayBuffer" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-class"><span class="n">TensorDictReplayBuffer</span></a>
<span class="kn">from</span> <span class="nn">torchrl.envs</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.EnvCreator.html#torchrl.envs.EnvCreator" title="torchrl.envs.EnvCreator" class="sphx-glr-backref-module-torchrl-envs sphx-glr-backref-type-py-class"><span class="n">EnvCreator</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv" class="sphx-glr-backref-module-torchrl-envs sphx-glr-backref-type-py-class"><span class="n">ParallelEnv</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.RewardScaling.html#torchrl.envs.transforms.RewardScaling" title="torchrl.envs.transforms.transforms.RewardScaling" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">RewardScaling</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter" title="torchrl.envs.transforms.transforms.StepCounter" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">StepCounter</span></a>
<span class="kn">from</span> <span class="nn">torchrl.envs.libs.gym</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.libs.gym.GymEnv.html#torchrl.envs.libs.gym.GymEnv" title="torchrl.envs.libs.gym.GymEnv" class="sphx-glr-backref-module-torchrl-envs-libs-gym sphx-glr-backref-type-py-function"><span class="n">GymEnv</span></a>
<span class="kn">from</span> <span class="nn">torchrl.envs.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames" title="torchrl.envs.transforms.transforms.CatFrames" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">CatFrames</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.CatTensors.html#torchrl.envs.transforms.CatTensors" title="torchrl.envs.transforms.transforms.CatTensors" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">CatTensors</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.transforms.Compose" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">Compose</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.GrayScale.html#torchrl.envs.transforms.GrayScale" title="torchrl.envs.transforms.transforms.GrayScale" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">GrayScale</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm" title="torchrl.envs.transforms.transforms.ObservationNorm" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">ObservationNorm</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.Resize.html#torchrl.envs.transforms.Resize" title="torchrl.envs.transforms.transforms.Resize" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.ToTensorImage.html#torchrl.envs.transforms.ToTensorImage" title="torchrl.envs.transforms.transforms.ToTensorImage" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">ToTensorImage</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv" title="torchrl.envs.transforms.transforms.TransformedEnv" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">TransformedEnv</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchrl.envs.utils</span> <span class="kn">import</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.set_interaction_mode.html#tensordict.nn.set_interaction_mode" title="tensordict.nn.set_interaction_mode" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_mode</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.utils.step_mdp.html#torchrl.envs.utils.step_mdp" title="torchrl.envs.utils.step_mdp" class="sphx-glr-backref-module-torchrl-envs-utils sphx-glr-backref-type-py-function"><span class="n">step_mdp</span></a>
<span class="kn">from</span> <span class="nn">torchrl.modules</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.DuelingCnnDQNet.html#torchrl.modules.DuelingCnnDQNet" title="torchrl.modules.DuelingCnnDQNet" class="sphx-glr-backref-module-torchrl-modules sphx-glr-backref-type-py-class"><span class="n">DuelingCnnDQNet</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class"><span class="n">EGreedyWrapper</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class"><span class="n">QValueActor</span></a>


<span class="k">def</span> <span class="nf">is_notebook</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">shell</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">if</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;ZMQInteractiveShell&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>  <span class="c1"># Jupyter notebook or qtconsole</span>
        <span class="k">elif</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;TerminalInteractiveShell&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Terminal running IPython</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Other type (?)</span>
    <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Probably standard Python interpreter</span>
</pre></div>
</div>
<section id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this heading">¶</a></h2>
<p>Let’s start with our hyperparameters. The following setting should work well
in practice, and the performance of the algorithm should hopefully not be
too sensitive to slight variations of these.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count" title="torch.cuda.device_count" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span></a><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
<section id="optimizer">
<h3>Optimizer<a class="headerlink" href="#optimizer" title="Permalink to this heading">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># the learning rate of the optimizer</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-3</span>
<span class="c1"># the beta parameters of Adam</span>
<span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
<span class="c1"># Optimization steps per batch collected (aka UPD or updates per data)</span>
<span class="n">n_optim</span> <span class="o">=</span> <span class="mi">8</span>
</pre></div>
</div>
</section>
<section id="dqn-parameters">
<h3>DQN parameters<a class="headerlink" href="#dqn-parameters" title="Permalink to this heading">¶</a></h3>
<p>gamma decay factor</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
</pre></div>
</div>
<p>lambda decay factor (see second the part with TD(<span class="math notranslate nohighlight">\(\lambda\)</span>)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lmbda</span> <span class="o">=</span> <span class="mf">0.95</span>
</pre></div>
</div>
<p>Smooth target network update decay parameter.
This loosely corresponds to a 1/(1-tau) interval with hard target network
update</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>
</pre></div>
</div>
</section>
<section id="data-collection-and-replay-buffer">
<h3>Data collection and replay buffer<a class="headerlink" href="#data-collection-and-replay-buffer" title="Permalink to this heading">¶</a></h3>
<p>Values to be used for proper training have been commented.</p>
<p>Total frames collected in the environment. In other implementations, the
user defines a maximum number of episodes.
This is harder to do with our data collectors since they return batches
of N collected frames, where N is a constant.
However, one can easily get the same restriction on number of episodes by
breaking the training loop when a certain number
episodes has been collected.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">total_frames</span> <span class="o">=</span> <span class="mi">5000</span>  <span class="c1"># 500000</span>
</pre></div>
</div>
<p>Random frames used to initialize the replay buffer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">init_random_frames</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># 1000</span>
</pre></div>
</div>
<p>Frames in each batch collected.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">frames_per_batch</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># 128</span>
</pre></div>
</div>
<p>Frames sampled from the replay buffer at each optimization step</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># 256</span>
</pre></div>
</div>
<p>Size of the replay buffer in terms of frames</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">buffer_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">total_frames</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
</pre></div>
</div>
<p>Number of environments run in parallel in each data collector</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_workers</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 8</span>
<span class="n">num_collectors</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 4</span>
</pre></div>
</div>
</section>
<section id="environment-and-exploration">
<h3>Environment and exploration<a class="headerlink" href="#environment-and-exploration" title="Permalink to this heading">¶</a></h3>
<p>We set the initial and final value of the epsilon factor in Epsilon-greedy
exploration.
Since our policy is deterministic, exploration is crucial: without it, the
only source of randomness would be the environment reset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">eps_greedy_val</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">eps_greedy_val_env</span> <span class="o">=</span> <span class="mf">0.005</span>
</pre></div>
</div>
<p>To speed up learning, we set the bias of the last layer of our value network
to a predefined value (this is not mandatory)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">init_bias</span> <span class="o">=</span> <span class="mf">2.0</span>
</pre></div>
</div>
<p><strong>Note</strong>: for fast rendering of the tutorial <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> hyperparameter
was set to a very low number. To get a reasonable performance, use a greater
value e.g. 500000</p>
</section>
</section>
<section id="building-the-environment">
<h2>Building the environment<a class="headerlink" href="#building-the-environment" title="Permalink to this heading">¶</a></h2>
<p>Our environment builder has two arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parallel</span></code>: determines whether multiple environments have to be run in
parallel. We stack the transforms after the
<a class="reference internal" href="../reference/generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.ParallelEnv</span></code></a> to take advantage
of vectorization of the operations on device, although this would
technically work with every single environment attached to its own set of
transforms.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">observation_norm_state_dict</span></code> will contain the normalizing constants for
the <code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.ObservationNorm</span></code> tranform.</p></li>
</ul>
<p>We will be using five transforms:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.ToTensorImage</span></code> will convert a <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">H,</span> <span class="pre">C]</span></code> uint8
tensor in a floating point tensor in the <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code> space with shape
<code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">W,</span> <span class="pre">H]</span></code>;</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.RewardScaling</span></code> to reduce the scale of the return;</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.GrayScale</span></code> will turn our image into grayscale;</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.Resize</span></code> will resize the image in a 64x64 format;</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.CatFrames</span></code> will concatenate an arbitrary number of
successive frames (<code class="docutils literal notranslate"><span class="pre">N=4</span></code>) in a single tensor along the channel dimension.
This is useful as a single image does not carry information about the
motion of the cartpole. Some memory about past observations and actions
is needed, either via a recurrent neural network or using a stack of
frames.</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.ObservationNorm</span></code> which will normalize our observations
given some custom summary statistics.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_env</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">observation_norm_state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">observation_norm_state_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">observation_norm_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;standard_normal&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
        <span class="n">base_env</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.ParallelEnv.html#torchrl.envs.ParallelEnv" title="torchrl.envs.ParallelEnv" class="sphx-glr-backref-module-torchrl-envs sphx-glr-backref-type-py-class"><span class="n">ParallelEnv</span></a><span class="p">(</span>
            <span class="n">num_workers</span><span class="p">,</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.EnvCreator.html#torchrl.envs.EnvCreator" title="torchrl.envs.EnvCreator" class="sphx-glr-backref-module-torchrl-envs sphx-glr-backref-type-py-class"><span class="n">EnvCreator</span></a><span class="p">(</span>
                <span class="k">lambda</span><span class="p">:</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.libs.gym.GymEnv.html#torchrl.envs.libs.gym.GymEnv" title="torchrl.envs.libs.gym.GymEnv" class="sphx-glr-backref-module-torchrl-envs-libs-gym sphx-glr-backref-type-py-function"><span class="n">GymEnv</span></a><span class="p">(</span>
                    <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">base_env</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.libs.gym.GymEnv.html#torchrl.envs.libs.gym.GymEnv" title="torchrl.envs.libs.gym.GymEnv" class="sphx-glr-backref-module-torchrl-envs-libs-gym sphx-glr-backref-type-py-function"><span class="n">GymEnv</span></a><span class="p">(</span>
            <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">from_pixels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixels_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>

    <span class="n">env</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.TransformedEnv.html#torchrl.envs.transforms.TransformedEnv" title="torchrl.envs.transforms.transforms.TransformedEnv" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">TransformedEnv</span></a><span class="p">(</span>
        <span class="n">base_env</span><span class="p">,</span>
        <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.Compose.html#torchrl.envs.transforms.Compose" title="torchrl.envs.transforms.transforms.Compose" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">Compose</span></a><span class="p">(</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.StepCounter.html#torchrl.envs.transforms.StepCounter" title="torchrl.envs.transforms.transforms.StepCounter" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">StepCounter</span></a><span class="p">(),</span>  <span class="c1"># to count the steps of each trajectory</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.ToTensorImage.html#torchrl.envs.transforms.ToTensorImage" title="torchrl.envs.transforms.transforms.ToTensorImage" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">ToTensorImage</span></a><span class="p">(),</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.RewardScaling.html#torchrl.envs.transforms.RewardScaling" title="torchrl.envs.transforms.transforms.RewardScaling" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">RewardScaling</span></a><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.GrayScale.html#torchrl.envs.transforms.GrayScale" title="torchrl.envs.transforms.transforms.GrayScale" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">GrayScale</span></a><span class="p">(),</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.Resize.html#torchrl.envs.transforms.Resize" title="torchrl.envs.transforms.transforms.Resize" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.CatFrames.html#torchrl.envs.transforms.CatFrames" title="torchrl.envs.transforms.transforms.CatFrames" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">CatFrames</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">),</span>
            <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.ObservationNorm.html#torchrl.envs.transforms.ObservationNorm" title="torchrl.envs.transforms.transforms.ObservationNorm" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">ObservationNorm</span></a><span class="p">(</span><span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">observation_norm_state_dict</span><span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">env</span>
</pre></div>
</div>
<section id="compute-normalizing-constants">
<h3>Compute normalizing constants<a class="headerlink" href="#compute-normalizing-constants" title="Permalink to this heading">¶</a></h3>
<p>To normalize images, we don’t want to normalize each pixel independently
with a full <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">W,</span> <span class="pre">H]</span></code> normalizing mask, but with simpler <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>
shaped loc and scale parameters. We will be using the <code class="docutils literal notranslate"><span class="pre">reduce_dim</span></code> argument
of <code class="xref py py-func docutils literal notranslate"><span class="pre">torchrl.envs.ObservationNorm.init_stats()</span></code> to instruct which
dimensions must be reduced, and the <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> parameter to ensure that
not all dimensions disappear in the process:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()</span>
<span class="n">test_env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">init_stats</span><span class="p">(</span>
    <span class="n">num_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">cat_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduce_dim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">keep_dims</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">observation_norm_state_dict</span> <span class="o">=</span> <span class="n">test_env</span><span class="o">.</span><span class="n">transform</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
<p>let’s check that normalizing constants have a size of <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> where
<code class="docutils literal notranslate"><span class="pre">C=4</span></code> (because of <code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.CatFrames</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">observation_norm_state_dict</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;standard_normal&#39;, tensor(True)), (&#39;loc&#39;, tensor([[[0.9921]],

        [[0.9921]],

        [[0.9921]],

        [[0.9921]]])), (&#39;scale&#39;, tensor([[[0.0784]],

        [[0.0784]],

        [[0.0784]],

        [[0.0785]]]))])
</pre></div>
</div>
</section>
</section>
<section id="building-the-model-deep-q-network">
<h2>Building the model (Deep Q-network)<a class="headerlink" href="#building-the-model-deep-q-network" title="Permalink to this heading">¶</a></h2>
<p>The following function builds a <a class="reference internal" href="../reference/generated/torchrl.modules.DuelingCnnDQNet.html#torchrl.modules.DuelingCnnDQNet" title="torchrl.modules.DuelingCnnDQNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.modules.DuelingCnnDQNet</span></code></a>
object which is a simple CNN followed by a two-layer MLP. The only trick used
here is that the action values (i.e. left and right action value) are
computed using</p>
<div class="math notranslate nohighlight">
\[val = b(obs) + v(obs) - \mathbb{E}[v(obs)]\]</div>
<p>where <span class="math notranslate nohighlight">\(b\)</span> is a <span class="math notranslate nohighlight">\(\# obs \rightarrow 1\)</span> function and <span class="math notranslate nohighlight">\(v\)</span> is a
<span class="math notranslate nohighlight">\(\# obs \rightarrow num_actions\)</span> function.</p>
<p>Our network is wrapped in a <code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.modules.QValueActor</span></code>, which will read the state-action
values, pick up the one with the maximum value and write all those results
in the input <a class="reference external" href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="(in tensordict vmain (0.0.2b+e22db6d ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">tensordict.TensorDict</span></code></a>.</p>
<section id="target-parameters">
<h3>Target parameters<a class="headerlink" href="#target-parameters" title="Permalink to this heading">¶</a></h3>
<p>Many off-policy RL algorithms use the concept of “target parameters” when it
comes to estimate the value of the <code class="docutils literal notranslate"><span class="pre">t+1</span></code> state or state-action pair.
The target parameters are lagged copies of the model parameters. Because
their predictions mismatch those of the current model configuration, they
help learning by putting a pessimistic bound on the value being estimated.
This is a powerful trick (known as “Double Q-Learning”) that is ubiquitous
in similar algorithms.</p>
</section>
<section id="functionalizing-modules">
<h3>Functionalizing modules<a class="headerlink" href="#functionalizing-modules" title="Permalink to this heading">¶</a></h3>
<p>One of the features of torchrl is its usage of functional modules: as the
same architecture is often used with multiple sets of parameters (e.g.
trainable and target parameters), we functionalize the modules and isolate
the various sets of parameters in separate tensordicts.</p>
<p>To this aim, we use <a class="reference external" href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.get_functional.html#tensordict.nn.get_functional" title="(in tensordict vmain (0.0.2b+e22db6d ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensordict.nn.get_functional()</span></code></a>, which augments
our modules with some extra feature that make them compatible with parameters
passed in the <code class="docutils literal notranslate"><span class="pre">TensorDict</span></code> format.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_model</span><span class="p">(</span><span class="n">dummy_env</span><span class="p">):</span>
    <span class="n">cnn_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;num_cells&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
        <span class="s2">&quot;kernel_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s2">&quot;strides&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s2">&quot;activation_class&quot;</span><span class="p">:</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU" title="torch.nn.ELU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span></a><span class="p">,</span>
        <span class="c1"># This can be used to reduce the size of the last layer of the CNN</span>
        <span class="c1"># &quot;squeeze_output&quot;: True,</span>
        <span class="c1"># &quot;aggregator_class&quot;: nn.AdaptiveAvgPool2d,</span>
        <span class="c1"># &quot;aggregator_kwargs&quot;: {&quot;output_size&quot;: (1, 1)},</span>
    <span class="p">}</span>
    <span class="n">mlp_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;depth&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;num_cells&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="mi">64</span><span class="p">,</span>
            <span class="mi">64</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;activation_class&quot;</span><span class="p">:</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU" title="torch.nn.ELU" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span></a><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">net</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.DuelingCnnDQNet.html#torchrl.modules.DuelingCnnDQNet" title="torchrl.modules.DuelingCnnDQNet" class="sphx-glr-backref-module-torchrl-modules sphx-glr-backref-type-py-class"><span class="n">DuelingCnnDQNet</span></a><span class="p">(</span>
        <span class="n">dummy_env</span><span class="o">.</span><span class="n">action_spec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cnn_kwargs</span><span class="p">,</span> <span class="n">mlp_kwargs</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">init_bias</span><span class="p">)</span>

    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class"><span class="n">QValueActor</span></a><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">in_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="n">spec</span><span class="o">=</span><span class="n">dummy_env</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># init actor: because the model is composed of lazy conv/linear layers,</span>
    <span class="c1"># we must pass a fake batch of data through it to instantiate them.</span>
    <span class="n">tensordict</span> <span class="o">=</span> <span class="n">dummy_env</span><span class="o">.</span><span class="n">fake_tensordict</span><span class="p">()</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="c1"># Make functional:</span>
    <span class="c1"># here&#39;s an explicit way of creating the parameters and buffer tensordict.</span>
    <span class="c1"># Alternatively, we could have used `params = make_functional(actor)` from</span>
    <span class="c1"># tensordict.nn</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class"><span class="n">TensorDict</span></a><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters" title="torch.nn.Module.named_parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">actor</span><span class="o">.</span><span class="n">named_parameters</span></a><span class="p">()},</span> <span class="p">[])</span>
    <span class="n">buffers</span> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class"><span class="n">TensorDict</span></a><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_buffers" title="torch.nn.Module.named_buffers" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">actor</span><span class="o">.</span><span class="n">named_buffers</span></a><span class="p">()},</span> <span class="p">[])</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.update" title="tensordict.TensorDict.update" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params</span><span class="o">.</span><span class="n">update</span></a><span class="p">(</span><span class="n">buffers</span><span class="p">)</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">.</span><span class="n">unflatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>  <span class="c1"># creates a nested TensorDict</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.get_functional.html#tensordict.nn.get_functional" title="tensordict.nn.get_functional" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-function"><span class="n">get_functional</span></a><span class="p">(</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">)</span>

    <span class="c1"># creating the target parameters is fairly easy with tensordict:</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_target</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.clone" title="tensordict.TensorDict.clone" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params</span><span class="o">.</span><span class="n">clone</span></a><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="c1"># we wrap our actor in an EGreedyWrapper for data collection</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class"><span class="n">EGreedyWrapper</span></a><span class="p">(</span>
        <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span>
        <span class="n">annealing_num_steps</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
        <span class="n">eps_init</span><span class="o">=</span><span class="n">eps_greedy_val</span><span class="p">,</span>
        <span class="n">eps_end</span><span class="o">=</span><span class="n">eps_greedy_val_env</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_target</span></a>


<span class="p">(</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">,</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">,</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_target</span></a><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">test_env</span><span class="p">)</span>
</pre></div>
</div>
<p>We represent the parameters and targets as flat structures, but unflattening
them is quite easy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_flat</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We will be using the adam optimizer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optim</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="nb">list</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.values" title="tensordict.TensorDict.values" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span></a><span class="p">()),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">)</span>
</pre></div>
</div>
<p>We create a test environment for evaluation of the policy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">(</span>
    <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">observation_norm_state_dict</span><span class="o">=</span><span class="n">observation_norm_state_dict</span>
<span class="p">)</span>
<span class="c1"># sanity check:</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">(</span><span class="n">test_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        step_count: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
</section>
<section id="collecting-and-storing-data">
<h2>Collecting and storing data<a class="headerlink" href="#collecting-and-storing-data" title="Permalink to this heading">¶</a></h2>
<section id="replay-buffers">
<h3>Replay buffers<a class="headerlink" href="#replay-buffers" title="Permalink to this heading">¶</a></h3>
<p>Replay buffers play a central role in off-policy RL algorithms such as DQN.
They constitute the dataset we will be sampling from during training.</p>
<p>Here, we will use a regular sampling strategy, although a prioritized RB
could improve the performance significantly.</p>
<p>We place the storage on disk using
<a class="reference internal" href="../reference/generated/torchrl.data.replay_buffers.storages.LazyMemmapStorage.html#torchrl.data.replay_buffers.storages.LazyMemmapStorage" title="torchrl.data.replay_buffers.storages.LazyMemmapStorage"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.data.replay_buffers.storages.LazyMemmapStorage</span></code></a> class. This
storage is created in a lazy manner: it will only be instantiated once the
first batch of data is passed to it.</p>
<p>The only requirement of this storage is that the data passed to it at write
time must always have the same shape.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer" title="torchrl.data.TensorDictReplayBuffer" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">replay_buffer</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer" title="torchrl.data.TensorDictReplayBuffer" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-class"><span class="n">TensorDictReplayBuffer</span></a><span class="p">(</span>
    <span class="n">storage</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.data.replay_buffers.storages.LazyMemmapStorage.html#torchrl.data.replay_buffers.storages.LazyMemmapStorage" title="torchrl.data.replay_buffers.storages.LazyMemmapStorage" class="sphx-glr-backref-module-torchrl-data-replay_buffers-storages sphx-glr-backref-type-py-class"><span class="n">LazyMemmapStorage</span></a><span class="p">(</span><span class="n">buffer_size</span><span class="p">),</span>
    <span class="n">prefetch</span><span class="o">=</span><span class="n">n_optim</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-collector">
<h3>Data collector<a class="headerlink" href="#data-collector" title="Permalink to this heading">¶</a></h3>
<p>As in <cite>PPO &lt;https://pytorch.org/rl/tutorials/coding_ppo.html&gt;</cite> and
<cite>DDPG &lt;https://pytorch.org/rl/tutorials/coding_ddpg.html&gt;</cite>, we will be using
a data collector as a dataloader in the outer loop.</p>
<p>We choose the following configuration: we will be running a series of
parallel environments synchronously in parallel in different collectors,
themselves running in parallel but asynchronously.
The advantage of this configuration is that we can balance the amount of
compute that is executed in batch with what we want to be executed
asynchronously. We encourage the reader to experiment how the collection
speed is impacted by modifying the number of collectors (ie the number of
environment constructors passed to the collector) and the number of
environment executed in parallel in each collector (controlled by the
<code class="docutils literal notranslate"><span class="pre">num_workers</span></code> hyperparameter).</p>
<p>When building the collector, we can choose on which device we want the
environment and policy to execute the operations through the <code class="docutils literal notranslate"><span class="pre">device</span></code>
keyword argument. The <code class="docutils literal notranslate"><span class="pre">storing_devices</span></code> argument will modify the
location of the data being collected: if the batches that we are gathering
have a considerable size, we may want to store them on a different location
than the device where the computation is happening. For asynchronous data
collectors such as ours, different storing devices mean that the data that
we collect won’t sit on the same device each time, which is something that
out training loop must account for. For simplicity, we set the devices to
the same value for all sub-collectors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_collector</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.html#torchrl.collectors.collectors.MultiaSyncDataCollector" title="torchrl.collectors.collectors.MultiaSyncDataCollector" class="sphx-glr-backref-module-torchrl-collectors-collectors sphx-glr-backref-type-py-class"><span class="n">MultiaSyncDataCollector</span></a><span class="p">(</span>
    <span class="c1"># ``num_collectors`` collectors, each with an set of `num_workers` environments being run in parallel</span>
    <span class="p">[</span>
        <span class="n">make_env</span><span class="p">(</span>
            <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">observation_norm_state_dict</span><span class="o">=</span><span class="n">observation_norm_state_dict</span>
        <span class="p">),</span>
    <span class="p">]</span>
    <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="n">policy</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
    <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
    <span class="c1"># this is the default behaviour: the collector runs in ``&quot;random&quot;`` (or explorative) mode</span>
    <span class="n">exploration_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="c1"># We set the all the devices to be identical. Below is an example of</span>
    <span class="c1"># heterogeneous devices</span>
    <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="n">storing_devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="c1"># devices=[f&quot;cuda:{i}&quot; for i in range(1, 1 + num_collectors)],</span>
    <span class="c1"># storing_devices=[f&quot;cuda:{i}&quot; for i in range(1, 1 + num_collectors)],</span>
    <span class="n">split_trajs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="training-loop-of-a-regular-dqn">
<h2>Training loop of a regular DQN<a class="headerlink" href="#training-loop-of-a-regular-dqn" title="Permalink to this heading">¶</a></h2>
<p>We’ll start with a simple implementation of DQN where the returns are
computed without bootstrapping, i.e.</p>
<div class="math notranslate nohighlight">
\[Q_{t}(s, a) = R(s, a) + \gamma * V_{t+1}(s)\]</div>
<p>where <span class="math notranslate nohighlight">\(Q(s, a)\)</span> is the Q-value of the current state-action pair,
<span class="math notranslate nohighlight">\(R(s, a)\)</span> is the result of the reward function, and <span class="math notranslate nohighlight">\(V(s)\)</span> is a
value function that returns 0 for terminating states.</p>
<p>We store the logs in a defaultdict:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">logs_exp1</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="n">prev_traj_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">total_frames</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_collector</span><span class="p">):</span>
    <span class="n">current_frames</span> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.numel" title="tensordict.TensorDict.numel" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">numel</span></a><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.view" title="tensordict.TensorDict.view" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">view</span></a><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># We store the values on the replay buffer, after placing them on CPU.</span>
    <span class="c1"># When called for the first time, this will instantiate our storage</span>
    <span class="c1"># object which will print its content.</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer.extend" title="torchrl.data.TensorDictReplayBuffer.extend" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-method"><span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span></a><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.cpu" title="tensordict.TensorDict.cpu" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">cpu</span></a><span class="p">())</span>

    <span class="c1"># some logging</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]):</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span> <span class="o">+</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="k">if</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_lengths&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;step_count&quot;</span><span class="p">][</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="c1"># check that we have enough data to start training</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">init_random_frames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_optim</span><span class="p">):</span>
            <span class="c1"># sample from the RB and send to device</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer.sample" title="torchrl.data.TensorDictReplayBuffer.sample" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-method"><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span></a><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.to" title="tensordict.TensorDict.to" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">sampled_data</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># collect data from RB</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span><span class="o">.</span><span class="n">dtype</span></a><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="c1"># Compute action value (of the action actually taken) at time t</span>
            <span class="c1"># By default, TorchRL uses one-hot encodings for discrete actions</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.select" title="tensordict.TensorDict.select" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">sampled_data</span><span class="o">.</span><span class="n">select</span></a><span class="p">(</span><span class="o">*</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a><span class="p">[</span><span class="s2">&quot;action_value&quot;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">=</span> <span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">*</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span><span class="o">.</span><span class="n">dtype</span></a><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">with</span> <a href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="c1"># compute best action value for the next step, using target parameters</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tdstep</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.utils.step_mdp.html#torchrl.envs.utils.step_mdp" title="torchrl.envs.utils.step_mdp" class="sphx-glr-backref-module-torchrl-envs-utils sphx-glr-backref-type-py-function"><span class="n">step_mdp</span></a><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">)</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">(</span>
                    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.select" title="tensordict.TensorDict.select" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">tdstep</span><span class="o">.</span><span class="n">select</span></a><span class="p">(</span><span class="o">*</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="o">.</span><span class="n">in_keys</span><span class="p">),</span>
                    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">=</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_target</span></a><span class="p">,</span>
                <span class="p">)[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exp_value</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span></a> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a><span class="p">)</span>
            <span class="k">assert</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exp_value</span></a><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># we use MSE loss but L1 or smooth L1 should also work</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html#torch.nn.functional.mse_loss" title="torch.nn.functional.mse_loss" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">exp_value</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="torch.Tensor.backward" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-method"><span class="n">error</span><span class="o">.</span><span class="n">backward</span></a><span class="p">()</span>

            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gv</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_" title="torch.nn.utils.clip_grad_norm_" class="sphx-glr-backref-module-torch-nn-utils sphx-glr-backref-type-py-function"><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span></a><span class="p">(</span><span class="nb">list</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.values" title="tensordict.TensorDict.values" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span></a><span class="p">()),</span> <span class="mi">1</span><span class="p">)</span>

            <a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step" title="torch.optim.Optimizer.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
            <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.zero_grad" title="torch.optim.Adam.zero_grad" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span></a><span class="p">()</span>

            <span class="c1"># update of the target parameters</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.apply" title="tensordict.TensorDict.apply" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_target</span><span class="o">.</span><span class="n">apply</span></a><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">p_orig</span><span class="p">:</span> <span class="n">p_orig</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">+</span> <span class="n">p_target</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">),</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.detach" title="tensordict.TensorDict.detach" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params</span><span class="o">.</span><span class="n">detach</span></a><span class="p">(),</span>
                <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper.step" title="torchrl.modules.tensordict_module.EGreedyWrapper.step" class="sphx-glr-backref-module-torchrl-modules-tensordict_module sphx-glr-backref-type-py-method"><span class="n">actor_explore</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

        <span class="c1"># Logging</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gv</span></a><span class="p">))</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">prev_traj_count</span> <span class="o">+</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">prev_traj_count</span> <span class="o">=</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.set_interaction_mode.html#tensordict.nn.set_interaction_mode" title="tensordict.nn.set_interaction_mode" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_mode</span></a><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">),</span> <a href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="c1"># execute a rollout. The `set_exploration_mode(&quot;mode&quot;)` has no effect here since the policy is deterministic, but we add it for completeness</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a> <span class="o">=</span> <span class="n">test_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span>
                    <span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                    <span class="n">policy</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_lengths_eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.shape" title="tensordict.TensorDict.shape" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-property"><span class="n">eval_rollout</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]):</span>
                <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.95</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_count_eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;error: </span><span class="si">{</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, value: </span><span class="si">{</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, test return: </span><span class="si">{</span><span class="n">logs_exp1</span><span class="p">[</span><span class="s1">&#39;evals&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="c1"># update policy weights</span>
    <span class="n">data_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/5000 [00:00&lt;?, ?it/s]
  1%|          | 32/5000 [00:00&lt;02:29, 33.15it/s]Creating a MemmapStorage...
The storage is being created:
        action: /tmp/tmp7biy5gn1, 0.0762939453125 Mb of storage (size: torch.Size([5000, 2])).
        action_value: /tmp/tmp_2nebxqe, 0.03814697265625 Mb of storage (size: torch.Size([5000, 2])).
        chosen_action_value: /tmp/tmp4dnt453y, 0.019073486328125 Mb of storage (size: torch.Size([5000, 1])).
        done: /tmp/tmp0psehw44, 0.00476837158203125 Mb of storage (size: torch.Size([5000, 1])).
        index: /tmp/tmptblul0wb, 0.019073486328125 Mb of storage (size: torch.Size([5000])).
        pixels: /tmp/tmpv6dbtec2, 312.5 Mb of storage (size: torch.Size([5000, 4, 64, 64])).
        reward: /tmp/tmpwjcjitqb, 0.019073486328125 Mb of storage (size: torch.Size([5000, 1])).
        step_count: /tmp/tmp3ra30ofd, 0.03814697265625 Mb of storage (size: torch.Size([5000])).
        (&#39;collector&#39;, &#39;traj_ids&#39;): /tmp/tmps5gpvu8_, 0.03814697265625 Mb of storage (size: torch.Size([5000])).
        (&#39;next&#39;, &#39;done&#39;): /tmp/tmp2d9q1ayn, 0.00476837158203125 Mb of storage (size: torch.Size([5000, 1])).
        (&#39;next&#39;, &#39;pixels&#39;): /tmp/tmpbqc6h749, 312.5 Mb of storage (size: torch.Size([5000, 4, 64, 64])).
        (&#39;next&#39;, &#39;reward&#39;): /tmp/tmpu6o_tjme, 0.019073486328125 Mb of storage (size: torch.Size([5000, 1])).
        (&#39;next&#39;, &#39;step_count&#39;): /tmp/tmp1nithgyh, 0.03814697265625 Mb of storage (size: torch.Size([5000])).

  1%|1         | 64/5000 [00:01&lt;01:46, 46.13it/s]
  2%|1         | 96/5000 [00:02&lt;01:43, 47.18it/s]
  3%|2         | 128/5000 [00:02&lt;01:50, 44.06it/s]
  3%|3         | 160/5000 [00:03&lt;01:43, 46.81it/s]
  4%|3         | 192/5000 [00:04&lt;01:38, 48.65it/s]
  4%|4         | 224/5000 [00:04&lt;01:34, 50.36it/s]
  5%|5         | 256/5000 [00:05&lt;01:32, 51.04it/s]
  6%|5         | 288/5000 [00:05&lt;01:32, 50.87it/s]
  6%|6         | 320/5000 [00:06&lt;01:31, 51.42it/s]
  7%|7         | 352/5000 [00:07&lt;01:29, 51.86it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:   7%|7         | 352/5000 [00:07&lt;01:29, 51.86it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:   8%|7         | 384/5000 [00:07&lt;01:33, 49.33it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:   8%|8         | 416/5000 [00:08&lt;01:30, 50.72it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:   9%|8         | 448/5000 [00:09&lt;01:30, 50.05it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  10%|9         | 480/5000 [00:09&lt;01:28, 50.87it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  10%|#         | 512/5000 [00:10&lt;01:29, 50.00it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  11%|#         | 544/5000 [00:11&lt;01:29, 49.72it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  12%|#1        | 576/5000 [00:11&lt;01:29, 49.26it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  12%|#2        | 608/5000 [00:12&lt;01:27, 49.99it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  13%|#2        | 640/5000 [00:12&lt;01:26, 50.56it/s]
error:  0.0621, value:  1.6399, test return:  1.0000:  13%|#3        | 672/5000 [00:13&lt;01:25, 50.48it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  13%|#3        | 672/5000 [00:14&lt;01:25, 50.48it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  14%|#4        | 704/5000 [00:14&lt;01:27, 48.93it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  15%|#4        | 736/5000 [00:14&lt;01:25, 49.99it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  15%|#5        | 768/5000 [00:15&lt;01:23, 50.87it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  16%|#6        | 800/5000 [00:16&lt;01:21, 51.74it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  17%|#6        | 832/5000 [00:16&lt;01:23, 50.19it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  17%|#7        | 864/5000 [00:17&lt;01:20, 51.33it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  18%|#7        | 896/5000 [00:17&lt;01:19, 51.93it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  19%|#8        | 928/5000 [00:18&lt;01:18, 51.56it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  19%|#9        | 960/5000 [00:19&lt;01:19, 50.71it/s]
error:  0.0533, value:  1.4559, test return:  0.9000:  20%|#9        | 992/5000 [00:19&lt;01:21, 49.22it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  20%|#9        | 992/5000 [00:20&lt;01:21, 49.22it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  20%|##        | 1024/5000 [00:20&lt;01:27, 45.21it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  21%|##1       | 1056/5000 [00:21&lt;01:24, 46.90it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  22%|##1       | 1088/5000 [00:22&lt;01:20, 48.76it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  22%|##2       | 1120/5000 [00:22&lt;01:17, 49.90it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  23%|##3       | 1152/5000 [00:23&lt;01:15, 50.77it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  24%|##3       | 1184/5000 [00:23&lt;01:14, 51.07it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  24%|##4       | 1216/5000 [00:24&lt;01:14, 50.95it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  25%|##4       | 1248/5000 [00:25&lt;01:13, 51.26it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  26%|##5       | 1280/5000 [00:25&lt;01:13, 50.78it/s]
error:  0.1812, value:  1.6425, test return:  1.0000:  26%|##6       | 1312/5000 [00:26&lt;01:11, 51.50it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  26%|##6       | 1312/5000 [00:27&lt;01:11, 51.50it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  27%|##6       | 1344/5000 [00:27&lt;01:13, 49.53it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  28%|##7       | 1376/5000 [00:27&lt;01:11, 50.47it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  28%|##8       | 1408/5000 [00:28&lt;01:10, 51.06it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  29%|##8       | 1440/5000 [00:28&lt;01:10, 50.80it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  29%|##9       | 1472/5000 [00:29&lt;01:11, 49.50it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  30%|###       | 1504/5000 [00:30&lt;01:12, 47.97it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  31%|###       | 1536/5000 [00:31&lt;01:13, 46.91it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  31%|###1      | 1568/5000 [00:31&lt;01:11, 47.83it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  32%|###2      | 1600/5000 [00:32&lt;01:08, 49.44it/s]
error:  0.0589, value:  1.4918, test return:  0.9000:  33%|###2      | 1632/5000 [00:32&lt;01:07, 49.98it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  33%|###2      | 1632/5000 [00:33&lt;01:07, 49.98it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  33%|###3      | 1664/5000 [00:33&lt;01:09, 48.33it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  34%|###3      | 1696/5000 [00:34&lt;01:06, 49.64it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  35%|###4      | 1728/5000 [00:34&lt;01:04, 51.06it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  35%|###5      | 1760/5000 [00:35&lt;01:04, 50.48it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  36%|###5      | 1792/5000 [00:36&lt;01:04, 50.07it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  36%|###6      | 1824/5000 [00:36&lt;01:02, 50.47it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  37%|###7      | 1856/5000 [00:37&lt;01:00, 51.73it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  38%|###7      | 1888/5000 [00:37&lt;01:00, 51.34it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  38%|###8      | 1920/5000 [00:38&lt;00:59, 52.00it/s]
error:  0.0142, value:  1.4841, test return:  1.0000:  39%|###9      | 1952/5000 [00:39&lt;01:00, 50.58it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  39%|###9      | 1952/5000 [00:39&lt;01:00, 50.58it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  40%|###9      | 1984/5000 [00:39&lt;01:03, 47.23it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  40%|####      | 2016/5000 [00:40&lt;01:04, 46.07it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  41%|####      | 2048/5000 [00:41&lt;01:02, 46.96it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  42%|####1     | 2080/5000 [00:41&lt;01:00, 48.11it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  42%|####2     | 2112/5000 [00:42&lt;00:58, 49.46it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  43%|####2     | 2144/5000 [00:43&lt;00:57, 49.31it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  44%|####3     | 2176/5000 [00:43&lt;00:55, 50.49it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  44%|####4     | 2208/5000 [00:44&lt;00:54, 51.25it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  45%|####4     | 2240/5000 [00:45&lt;00:52, 52.11it/s]
error:  0.0126, value:  1.6382, test return:  1.0000:  45%|####5     | 2272/5000 [00:45&lt;00:52, 52.30it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  45%|####5     | 2272/5000 [00:46&lt;00:52, 52.30it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  46%|####6     | 2304/5000 [00:46&lt;00:53, 50.37it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  47%|####6     | 2336/5000 [00:46&lt;00:51, 51.43it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  47%|####7     | 2368/5000 [00:47&lt;00:51, 51.58it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  48%|####8     | 2400/5000 [00:48&lt;00:49, 52.59it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  49%|####8     | 2432/5000 [00:48&lt;00:49, 52.03it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  49%|####9     | 2464/5000 [00:49&lt;00:51, 49.32it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  50%|####9     | 2496/5000 [00:50&lt;00:51, 48.20it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  51%|#####     | 2528/5000 [00:50&lt;00:51, 48.22it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  51%|#####1    | 2560/5000 [00:51&lt;00:50, 48.38it/s]
error:  0.0279, value:  1.4272, test return:  0.9000:  52%|#####1    | 2592/5000 [00:52&lt;00:48, 49.46it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  52%|#####1    | 2592/5000 [00:52&lt;00:48, 49.46it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  52%|#####2    | 2624/5000 [00:52&lt;00:48, 49.02it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  53%|#####3    | 2656/5000 [00:53&lt;00:46, 50.63it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  54%|#####3    | 2688/5000 [00:53&lt;00:44, 51.71it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  54%|#####4    | 2720/5000 [00:54&lt;00:44, 51.63it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  55%|#####5    | 2752/5000 [00:55&lt;00:42, 52.52it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  56%|#####5    | 2784/5000 [00:55&lt;00:41, 53.38it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  56%|#####6    | 2816/5000 [00:56&lt;00:40, 53.67it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  57%|#####6    | 2848/5000 [00:56&lt;00:39, 54.04it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  58%|#####7    | 2880/5000 [00:57&lt;00:39, 54.36it/s]
error:  0.0413, value:  1.4586, test return:  1.0000:  58%|#####8    | 2912/5000 [00:58&lt;00:38, 54.63it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  58%|#####8    | 2912/5000 [00:58&lt;00:38, 54.63it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  59%|#####8    | 2944/5000 [00:58&lt;00:40, 50.30it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  60%|#####9    | 2976/5000 [00:59&lt;00:40, 50.37it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  60%|######    | 3008/5000 [01:00&lt;00:40, 48.91it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  61%|######    | 3040/5000 [01:00&lt;00:41, 46.79it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  61%|######1   | 3072/5000 [01:01&lt;00:41, 46.82it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  62%|######2   | 3104/5000 [01:02&lt;00:38, 48.64it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  63%|######2   | 3136/5000 [01:02&lt;00:37, 49.50it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  63%|######3   | 3168/5000 [01:03&lt;00:35, 50.91it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  64%|######4   | 3200/5000 [01:03&lt;00:34, 51.65it/s]
error:  0.0247, value:  1.5781, test return:  1.7000:  65%|######4   | 3232/5000 [01:04&lt;00:33, 52.02it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  65%|######4   | 3232/5000 [01:05&lt;00:33, 52.02it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  65%|######5   | 3264/5000 [01:05&lt;00:41, 41.62it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  66%|######5   | 3296/5000 [01:06&lt;00:37, 45.35it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  67%|######6   | 3328/5000 [01:06&lt;00:35, 47.19it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  67%|######7   | 3360/5000 [01:07&lt;00:34, 47.78it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  68%|######7   | 3392/5000 [01:08&lt;00:32, 49.45it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  68%|######8   | 3424/5000 [01:08&lt;00:30, 50.97it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  69%|######9   | 3456/5000 [01:09&lt;00:30, 49.98it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  70%|######9   | 3488/5000 [01:10&lt;00:30, 49.06it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  70%|#######   | 3520/5000 [01:10&lt;00:31, 47.32it/s]
error:  0.0803, value:  1.5503, test return:  6.4000:  71%|#######1  | 3552/5000 [01:11&lt;00:30, 47.40it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  71%|#######1  | 3552/5000 [01:12&lt;00:30, 47.40it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  72%|#######1  | 3584/5000 [01:12&lt;00:32, 43.33it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  72%|#######2  | 3616/5000 [01:12&lt;00:29, 46.24it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  73%|#######2  | 3648/5000 [01:13&lt;00:28, 48.17it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  74%|#######3  | 3680/5000 [01:14&lt;00:26, 49.41it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  74%|#######4  | 3712/5000 [01:14&lt;00:25, 50.31it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  75%|#######4  | 3744/5000 [01:15&lt;00:24, 51.63it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  76%|#######5  | 3776/5000 [01:15&lt;00:23, 52.28it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  76%|#######6  | 3808/5000 [01:16&lt;00:22, 52.02it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  77%|#######6  | 3840/5000 [01:17&lt;00:21, 53.00it/s]
error:  0.0601, value:  1.6302, test return:  3.5000:  77%|#######7  | 3872/5000 [01:17&lt;00:21, 52.39it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  77%|#######7  | 3872/5000 [01:19&lt;00:21, 52.39it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  78%|#######8  | 3904/5000 [01:19&lt;00:31, 34.86it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  79%|#######8  | 3936/5000 [01:20&lt;00:31, 34.05it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  79%|#######9  | 3968/5000 [01:21&lt;00:28, 36.41it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  80%|########  | 4000/5000 [01:21&lt;00:25, 39.28it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  81%|########  | 4032/5000 [01:22&lt;00:22, 42.43it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  81%|########1 | 4064/5000 [01:22&lt;00:20, 45.48it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  82%|########1 | 4096/5000 [01:23&lt;00:19, 46.80it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  83%|########2 | 4128/5000 [01:24&lt;00:17, 48.46it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  83%|########3 | 4160/5000 [01:24&lt;00:16, 50.06it/s]
error:  0.0725, value:  1.2328, test return:  10.2000:  84%|########3 | 4192/5000 [01:25&lt;00:15, 50.85it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  84%|########3 | 4192/5000 [01:26&lt;00:15, 50.85it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  84%|########4 | 4224/5000 [01:26&lt;00:17, 43.92it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  85%|########5 | 4256/5000 [01:26&lt;00:15, 46.64it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  86%|########5 | 4288/5000 [01:27&lt;00:14, 49.20it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  86%|########6 | 4320/5000 [01:28&lt;00:13, 50.92it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  87%|########7 | 4352/5000 [01:28&lt;00:12, 52.02it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  88%|########7 | 4384/5000 [01:29&lt;00:12, 50.56it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  88%|########8 | 4416/5000 [01:30&lt;00:12, 48.61it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  89%|########8 | 4448/5000 [01:30&lt;00:11, 46.80it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  90%|########9 | 4480/5000 [01:31&lt;00:10, 47.38it/s]
error:  0.0503, value:  1.5821, test return:  4.1000:  90%|######### | 4512/5000 [01:32&lt;00:09, 49.03it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  90%|######### | 4512/5000 [01:32&lt;00:09, 49.03it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  91%|######### | 4544/5000 [01:32&lt;00:10, 45.56it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  92%|#########1| 4576/5000 [01:33&lt;00:08, 48.08it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  92%|#########2| 4608/5000 [01:34&lt;00:07, 49.17it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  93%|#########2| 4640/5000 [01:34&lt;00:07, 50.21it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  93%|#########3| 4672/5000 [01:35&lt;00:06, 50.91it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  94%|#########4| 4704/5000 [01:35&lt;00:05, 51.72it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  95%|#########4| 4736/5000 [01:36&lt;00:04, 53.13it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  95%|#########5| 4768/5000 [01:37&lt;00:04, 53.05it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  96%|#########6| 4800/5000 [01:37&lt;00:03, 52.68it/s]
error:  0.1373, value:  1.9152, test return:  2.6000:  97%|#########6| 4832/5000 [01:38&lt;00:03, 53.71it/s]
error:  0.1208, value:  1.2684, test return:  4.4000:  97%|#########6| 4832/5000 [01:39&lt;00:03, 53.71it/s]
error:  0.1208, value:  1.2684, test return:  4.4000:  97%|#########7| 4864/5000 [01:39&lt;00:03, 42.93it/s]
error:  0.1208, value:  1.2684, test return:  4.4000:  98%|#########7| 4896/5000 [01:40&lt;00:02, 44.06it/s]
error:  0.1208, value:  1.2684, test return:  4.4000:  99%|#########8| 4928/5000 [01:40&lt;00:01, 45.90it/s]
error:  0.1208, value:  1.2684, test return:  4.4000:  99%|#########9| 4960/5000 [01:41&lt;00:00, 47.18it/s]
error:  0.1208, value:  1.2684, test return:  4.4000: 100%|#########9| 4992/5000 [01:41&lt;00:00, 48.55it/s]
error:  0.1208, value:  1.2684, test return:  4.4000: : 5024it [01:42, 49.98it/s]
</pre></div>
</div>
<p>We write a custom plot function to display the performance of our algorithm</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">])</span> <span class="p">:],</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (eval)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">])</span> <span class="p">:],</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg of returns (eval)&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;trajectory length (= return)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">])</span> <span class="p">:],</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">])</span> <span class="p">:],</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;trajectories collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">])</span> <span class="p">:],</span> <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">])</span> <span class="p">:],</span> <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">])</span> <span class="p">:],</span>
        <span class="n">logs</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;grad norm&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;traj_lengths&quot;</span><span class="p">]):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;traj_lengths&quot;</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;batches&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;traj length (training)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_notebook</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The performance of the policy can be measured as the length of trajectories.
As we can see on the results of the <code class="xref py py-func docutils literal notranslate"><span class="pre">plot()</span></code> function, the performance
of the policy increases, albeit slowly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">logs_exp1</span><span class="p">,</span> <span class="s2">&quot;dqn_td0.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="Cart Pole results with TD(0)" src="../_images/dqn_td0.png" />
</figure>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shutting down&quot;</span><span class="p">)</span>
<span class="n">data_collector</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
<span class="k">del</span> <span class="n">data_collector</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>shutting down
</pre></div>
</div>
</section>
<section id="dqn-with-td-lambda">
<h2>DQN with TD(<span class="math notranslate nohighlight">\(\lambda\)</span>)<a class="headerlink" href="#dqn-with-td-lambda" title="Permalink to this heading">¶</a></h2>
<p>We can improve the above algorithm by getting a better estimate of the
return, using not only the next state value but the whole sequence of rewards
and values that follow a particular step.</p>
<p>TorchRL provides a vectorized version of TD(lambda) named
<a class="reference internal" href="../reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.html#torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate" title="torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate"><code class="xref py py-func docutils literal notranslate"><span class="pre">torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate()</span></code></a>.
We’ll use this to obtain a target value that the value network will be
trained to match.</p>
<p>The big difference in this implementation is that we’ll store entire
trajectories and not single steps in the replay buffer. This will be done
automatically as long as we’re not “flattening” the tensordict collected:
by keeping a shape <code class="docutils literal notranslate"><span class="pre">[Batch</span> <span class="pre">x</span> <span class="pre">timesteps]</span></code> and giving this
to the RB, we’ll be creating a replay buffer of size
<code class="docutils literal notranslate"><span class="pre">[Capacity</span> <span class="pre">x</span> <span class="pre">timesteps]</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchrl.objectives.value.functional</span> <span class="kn">import</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.html#torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate" title="torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate" class="sphx-glr-backref-module-torchrl-objectives-value-functional sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vec_td_lambda_advantage_estimate</span></a>
</pre></div>
</div>
<p>We reset the actor parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span>
    <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">,</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">,</span>
    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_target</span></a><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">test_env</span><span class="p">)</span>
<a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_flat</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

<a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optim</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="nb">list</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.values" title="tensordict.TensorDict.values" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span></a><span class="p">()),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">)</span>
<span class="n">test_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">(</span>
    <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">observation_norm_state_dict</span><span class="o">=</span><span class="n">observation_norm_state_dict</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">(</span><span class="n">test_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorDict(
    fields={
        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),
        action_value: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),
        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),
        pixels: Tensor(shape=torch.Size([4, 64, 64]), device=cpu, dtype=torch.float32, is_shared=False),
        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
        step_count: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},
    batch_size=torch.Size([]),
    device=cpu,
    is_shared=False)
</pre></div>
</div>
</section>
<section id="data-replay-buffer-and-collector">
<h2>Data: Replay buffer and collector<a class="headerlink" href="#data-replay-buffer-and-collector" title="Permalink to this heading">¶</a></h2>
<p>We need to build a new replay buffer of the appropriate size:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">max_size</span> <span class="o">=</span> <span class="n">frames_per_batch</span> <span class="o">//</span> <span class="n">num_workers</span>

<a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer" title="torchrl.data.TensorDictReplayBuffer" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">replay_buffer</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer" title="torchrl.data.TensorDictReplayBuffer" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-class"><span class="n">TensorDictReplayBuffer</span></a><span class="p">(</span>
    <span class="n">storage</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.data.replay_buffers.storages.LazyMemmapStorage.html#torchrl.data.replay_buffers.storages.LazyMemmapStorage" title="torchrl.data.replay_buffers.storages.LazyMemmapStorage" class="sphx-glr-backref-module-torchrl-data-replay_buffers-storages sphx-glr-backref-type-py-class"><span class="n">LazyMemmapStorage</span></a><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">buffer_size</span> <span class="o">//</span> <span class="n">max_size</span><span class="p">)),</span>
    <span class="n">prefetch</span><span class="o">=</span><span class="n">n_optim</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data_collector</span> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.html#torchrl.collectors.collectors.MultiaSyncDataCollector" title="torchrl.collectors.collectors.MultiaSyncDataCollector" class="sphx-glr-backref-module-torchrl-collectors-collectors sphx-glr-backref-type-py-class"><span class="n">MultiaSyncDataCollector</span></a><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">make_env</span><span class="p">(</span>
            <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">observation_norm_state_dict</span><span class="o">=</span><span class="n">observation_norm_state_dict</span>
        <span class="p">),</span>
    <span class="p">]</span>
    <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="n">policy</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper" title="torchrl.modules.tensordict_module.exploration.EGreedyWrapper" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-exploration sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor_explore</span></a><span class="p">,</span>
    <span class="n">frames_per_batch</span><span class="o">=</span><span class="n">frames_per_batch</span><span class="p">,</span>
    <span class="n">total_frames</span><span class="o">=</span><span class="n">total_frames</span><span class="p">,</span>
    <span class="n">exploration_mode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="n">storing_devices</span><span class="o">=</span><span class="p">[</span><span class="n">device</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_collectors</span><span class="p">,</span>
    <span class="c1"># devices=[f&quot;cuda:{i}&quot; for i in range(1, 1 + num_collectors)],</span>
    <span class="c1"># storing_devices=[f&quot;cuda:{i}&quot; for i in range(1, 1 + num_collectors)],</span>
    <span class="n">split_trajs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">logs_exp2</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="n">prev_traj_count</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>error:  0.1208, value:  1.2684, test return:  4.4000: : 5024it [02:02, 49.98it/s]
</pre></div>
</div>
</section>
<section id="training-loop">
<h2>Training loop<a class="headerlink" href="#training-loop" title="Permalink to this heading">¶</a></h2>
<p>There are very few differences with the training loop above:</p>
<ul class="simple">
<li><p>The tensordict received by the collector is used as-is, without being
flattened (recall the <code class="docutils literal notranslate"><span class="pre">data.view(-1)</span></code> above), to keep the temporal
relation between consecutive steps.</p></li>
<li><p>We use <code class="xref py py-func docutils literal notranslate"><span class="pre">vec_td_lambda_advantage_estimate()</span></code> to compute the target
value.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">total_frames</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_collector</span><span class="p">):</span>
    <span class="n">current_frames</span> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.numel" title="tensordict.TensorDict.numel" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">numel</span></a><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer.extend" title="torchrl.data.TensorDictReplayBuffer.extend" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-method"><span class="n">replay_buffer</span><span class="o">.</span><span class="n">extend</span></a><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.cpu" title="tensordict.TensorDict.cpu" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">data</span><span class="o">.</span><span class="n">cpu</span></a><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]):</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span> <span class="o">+</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

    <span class="k">if</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_lengths&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;step_count&quot;</span><span class="p">][</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">init_random_frames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_optim</span><span class="p">):</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.data.TensorDictReplayBuffer.html#torchrl.data.TensorDictReplayBuffer.sample" title="torchrl.data.TensorDictReplayBuffer.sample" class="sphx-glr-backref-module-torchrl-data sphx-glr-backref-type-py-method"><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span></a><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">max_size</span><span class="p">)</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.clone" title="tensordict.TensorDict.clone" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">sampled_data</span><span class="o">.</span><span class="n">clone</span></a><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span><span class="o">.</span><span class="n">dtype</span></a><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.select" title="tensordict.TensorDict.select" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">sampled_data</span><span class="o">.</span><span class="n">select</span></a><span class="p">(</span><span class="o">*</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="o">.</span><span class="n">in_keys</span><span class="p">)</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">=</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data_out</span></a><span class="p">[</span><span class="s2">&quot;action_value&quot;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">=</span> <span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a> <span class="o">*</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span><span class="o">.</span><span class="n">dtype</span></a><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="k">with</span> <a href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tdstep</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.utils.step_mdp.html#torchrl.envs.utils.step_mdp" title="torchrl.envs.utils.step_mdp" class="sphx-glr-backref-module-torchrl-envs-utils sphx-glr-backref-type-py-function"><span class="n">step_mdp</span></a><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sampled_data</span></a><span class="p">)</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">factor</span></a><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))(</span>
                    <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.select" title="tensordict.TensorDict.select" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">tdstep</span><span class="o">.</span><span class="n">select</span></a><span class="p">(</span><span class="o">*</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="o">.</span><span class="n">in_keys</span><span class="p">),</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params</span></a>
                <span class="p">)</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a><span class="p">[</span><span class="s2">&quot;chosen_action_value&quot;</span><span class="p">]</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a> <span class="o">=</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.html#torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate" title="torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate" class="sphx-glr-backref-module-torchrl-objectives-value-functional sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vec_td_lambda_advantage_estimate</span></a><span class="p">(</span>
                <span class="n">gamma</span><span class="p">,</span>
                <span class="n">lmbda</span><span class="p">,</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="p">,</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">next_value</span></a><span class="p">,</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reward</span></a><span class="p">,</span>
                <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">done</span></a><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="torch.Tensor.backward" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-method"><span class="n">error</span><span class="o">.</span><span class="n">backward</span></a><span class="p">()</span>

            <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gv</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_" title="torch.nn.utils.clip_grad_norm_" class="sphx-glr-backref-module-torch-nn-utils sphx-glr-backref-type-py-function"><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span></a><span class="p">(</span><span class="nb">list</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.values" title="tensordict.TensorDict.values" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_flat</span><span class="o">.</span><span class="n">values</span></a><span class="p">()),</span> <span class="mi">1</span><span class="p">)</span>

            <a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step" title="torch.optim.Optimizer.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
            <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.zero_grad" title="torch.optim.Adam.zero_grad" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span></a><span class="p">()</span>

            <span class="c1"># update of the target parameters</span>
            <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.apply" title="tensordict.TensorDict.apply" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params_target</span><span class="o">.</span><span class="n">apply</span></a><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">p_orig</span><span class="p">:</span> <span class="n">p_orig</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">+</span> <span class="n">p_target</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">),</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.detach" title="tensordict.TensorDict.detach" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-method"><span class="n">params</span><span class="o">.</span><span class="n">detach</span></a><span class="p">(),</span>
                <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.html#torchrl.modules.tensordict_module.EGreedyWrapper.step" title="torchrl.modules.tensordict_module.EGreedyWrapper.step" class="sphx-glr-backref-module-torchrl-modules-tensordict_module sphx-glr-backref-type-py-method"><span class="n">actor_explore</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><span class="n">current_frames</span><span class="p">)</span>

        <span class="c1"># Logging</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;grad_vals&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gv</span></a><span class="p">))</span>

        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;losses&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">prev_traj_count</span> <span class="o">+</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">prev_traj_count</span> <span class="o">=</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.nn.set_interaction_mode.html#tensordict.nn.set_interaction_mode" title="tensordict.nn.set_interaction_mode" class="sphx-glr-backref-module-tensordict-nn sphx-glr-backref-type-py-class"><span class="n">set_exploration_mode</span></a><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">),</span> <a href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="c1"># execute a rollout. The `set_exploration_mode(&quot;mode&quot;)` has</span>
                <span class="c1"># no effect here since the policy is deterministic, but we add</span>
                <span class="c1"># it for completeness</span>
                <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a> <span class="o">=</span> <span class="n">test_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span>
                    <span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                    <span class="n">policy</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_lengths_eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict.shape" title="tensordict.TensorDict.shape" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-property"><span class="n">eval_rollout</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a><span class="p">[</span><span class="s2">&quot;next&quot;</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]):</span>
                <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.95</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_count_eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_count&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;error: </span><span class="si">{</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">error</span></a><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, value: </span><span class="si">{</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">action_value</span></a><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">, test return: </span><span class="si">{</span><span class="n">logs_exp2</span><span class="p">[</span><span class="s1">&#39;evals&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2"> 4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="c1"># update policy weights</span>
    <span class="n">data_collector</span><span class="o">.</span><span class="n">update_policy_weights_</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/5000 [00:00&lt;?, ?it/s]
error:  0.1208, value:  1.2684, test return:  4.4000: : 5024it [02:04, 40.31it/s]


  1%|          | 32/5000 [00:00&lt;01:53, 43.92it/s]Creating a MemmapStorage...
The storage is being created:
        _batch_size: /tmp/tmpve48c4ej, 0.00238800048828125 Mb of storage (size: torch.Size([313, 1])).
        action: /tmp/tmpn6f4alpq, 0.076416015625 Mb of storage (size: torch.Size([313, 16, 2])).
        action_value: /tmp/tmpv2ijgjpl, 0.0382080078125 Mb of storage (size: torch.Size([313, 16, 2])).
        chosen_action_value: /tmp/tmp_v4ymway, 0.01910400390625 Mb of storage (size: torch.Size([313, 16, 1])).
        done: /tmp/tmpe91ss7xl, 0.0047760009765625 Mb of storage (size: torch.Size([313, 16, 1])).
        index: /tmp/tmp7qnyi1ze, 0.001194000244140625 Mb of storage (size: torch.Size([313])).
        pixels: /tmp/tmp51c09u_x, 313.0 Mb of storage (size: torch.Size([313, 16, 4, 64, 64])).
        reward: /tmp/tmpjvh9o0qr, 0.01910400390625 Mb of storage (size: torch.Size([313, 16, 1])).
        step_count: /tmp/tmpi553irkt, 0.0382080078125 Mb of storage (size: torch.Size([313, 16])).
        (&#39;collector&#39;, &#39;traj_ids&#39;): /tmp/tmper_r0_ku, 0.0382080078125 Mb of storage (size: torch.Size([313, 16])).
        (&#39;next&#39;, &#39;done&#39;): /tmp/tmph0flduod, 0.0047760009765625 Mb of storage (size: torch.Size([313, 16, 1])).
        (&#39;next&#39;, &#39;pixels&#39;): /tmp/tmp7imorowx, 313.0 Mb of storage (size: torch.Size([313, 16, 4, 64, 64])).
        (&#39;next&#39;, &#39;reward&#39;): /tmp/tmp0x_q176y, 0.01910400390625 Mb of storage (size: torch.Size([313, 16, 1])).
        (&#39;next&#39;, &#39;step_count&#39;): /tmp/tmp3zk_xfsf, 0.0382080078125 Mb of storage (size: torch.Size([313, 16])).


  1%|1         | 64/5000 [00:00&lt;01:10, 70.12it/s]

  2%|1         | 96/5000 [00:01&lt;01:17, 62.89it/s]

  3%|2         | 128/5000 [00:02&lt;01:40, 48.45it/s]

  3%|3         | 160/5000 [00:03&lt;01:37, 49.44it/s]

  4%|3         | 192/5000 [00:03&lt;01:36, 49.97it/s]

  4%|4         | 224/5000 [00:04&lt;01:37, 48.91it/s]

  5%|5         | 256/5000 [00:05&lt;01:40, 47.38it/s]

  6%|5         | 288/5000 [00:05&lt;01:42, 46.18it/s]

  6%|6         | 320/5000 [00:06&lt;01:41, 46.33it/s]

  7%|7         | 352/5000 [00:07&lt;01:39, 46.89it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:   7%|7         | 352/5000 [00:07&lt;01:39, 46.89it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:   8%|7         | 384/5000 [00:07&lt;01:40, 45.99it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:   8%|8         | 416/5000 [00:08&lt;01:36, 47.43it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:   9%|8         | 448/5000 [00:09&lt;01:35, 47.84it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  10%|9         | 480/5000 [00:09&lt;01:33, 48.40it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  10%|#         | 512/5000 [00:10&lt;01:30, 49.60it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  11%|#         | 544/5000 [00:11&lt;01:28, 50.49it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  12%|#1        | 576/5000 [00:11&lt;01:26, 50.89it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  12%|#2        | 608/5000 [00:12&lt;01:25, 51.18it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  13%|#2        | 640/5000 [00:12&lt;01:25, 51.18it/s]

error:  0.6139, value:  1.5514, test return:  1.1000:  13%|#3        | 672/5000 [00:13&lt;01:24, 51.45it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  13%|#3        | 672/5000 [00:14&lt;01:24, 51.45it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  14%|#4        | 704/5000 [00:14&lt;01:26, 49.59it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  15%|#4        | 736/5000 [00:14&lt;01:26, 49.07it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  15%|#5        | 768/5000 [00:15&lt;01:28, 48.05it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  16%|#6        | 800/5000 [00:16&lt;01:27, 47.92it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  17%|#6        | 832/5000 [00:16&lt;01:26, 48.22it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  17%|#7        | 864/5000 [00:17&lt;01:24, 49.05it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  18%|#7        | 896/5000 [00:18&lt;01:23, 49.40it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  19%|#8        | 928/5000 [00:18&lt;01:21, 50.02it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  19%|#9        | 960/5000 [00:19&lt;01:20, 50.22it/s]

error:  0.2171, value:  1.0946, test return:  0.8000:  20%|#9        | 992/5000 [00:20&lt;01:19, 50.22it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  20%|#9        | 992/5000 [00:20&lt;01:19, 50.22it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  20%|##        | 1024/5000 [00:20&lt;01:23, 47.82it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  21%|##1       | 1056/5000 [00:21&lt;01:21, 48.29it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  22%|##1       | 1088/5000 [00:22&lt;01:19, 49.24it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  22%|##2       | 1120/5000 [00:22&lt;01:17, 50.16it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  23%|##3       | 1152/5000 [00:23&lt;01:16, 50.52it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  24%|##3       | 1184/5000 [00:23&lt;01:15, 50.74it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  24%|##4       | 1216/5000 [00:24&lt;01:17, 48.77it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  25%|##4       | 1248/5000 [00:25&lt;01:19, 47.38it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  26%|##5       | 1280/5000 [00:26&lt;01:21, 45.86it/s]

error:  0.0966, value:  0.9324, test return:  1.1000:  26%|##6       | 1312/5000 [00:26&lt;01:18, 46.79it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  26%|##6       | 1312/5000 [00:27&lt;01:18, 46.79it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  27%|##6       | 1344/5000 [00:27&lt;01:29, 40.69it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  28%|##7       | 1376/5000 [00:28&lt;01:23, 43.25it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  28%|##8       | 1408/5000 [00:29&lt;01:18, 45.52it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  29%|##8       | 1440/5000 [00:29&lt;01:15, 47.32it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  29%|##9       | 1472/5000 [00:30&lt;01:13, 48.30it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  30%|###       | 1504/5000 [00:30&lt;01:12, 48.25it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  31%|###       | 1536/5000 [00:31&lt;01:13, 47.39it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  31%|###1      | 1568/5000 [00:32&lt;01:10, 48.94it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  32%|###2      | 1600/5000 [00:32&lt;01:08, 49.39it/s]

error:  1.2596, value:  2.0438, test return:  4.4000:  33%|###2      | 1632/5000 [00:33&lt;01:08, 49.30it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  33%|###2      | 1632/5000 [00:34&lt;01:08, 49.30it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  33%|###3      | 1664/5000 [00:34&lt;01:11, 46.89it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  34%|###3      | 1696/5000 [00:35&lt;01:10, 46.66it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  35%|###4      | 1728/5000 [00:35&lt;01:11, 45.83it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  35%|###5      | 1760/5000 [00:36&lt;01:10, 45.82it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  36%|###5      | 1792/5000 [00:37&lt;01:08, 46.71it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  36%|###6      | 1824/5000 [00:37&lt;01:06, 48.03it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  37%|###7      | 1856/5000 [00:38&lt;01:04, 48.68it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  38%|###7      | 1888/5000 [00:38&lt;01:03, 49.11it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  38%|###8      | 1920/5000 [00:39&lt;01:01, 50.12it/s]

error:  0.1777, value:  1.0389, test return:  1.0000:  39%|###9      | 1952/5000 [00:40&lt;01:00, 50.38it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  39%|###9      | 1952/5000 [00:41&lt;01:00, 50.38it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  40%|###9      | 1984/5000 [00:41&lt;01:11, 41.91it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  40%|####      | 2016/5000 [00:41&lt;01:07, 44.51it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  41%|####      | 2048/5000 [00:42&lt;01:03, 46.34it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  42%|####1     | 2080/5000 [00:43&lt;01:01, 47.62it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  42%|####2     | 2112/5000 [00:43&lt;00:59, 48.51it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  43%|####2     | 2144/5000 [00:44&lt;01:00, 47.51it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  44%|####3     | 2176/5000 [00:45&lt;00:58, 47.88it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  44%|####4     | 2208/5000 [00:45&lt;00:59, 46.55it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  45%|####4     | 2240/5000 [00:46&lt;01:02, 44.29it/s]

error:  0.3791, value:  1.5358, test return:  5.4000:  45%|####5     | 2272/5000 [00:47&lt;00:59, 45.47it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  45%|####5     | 2272/5000 [00:48&lt;00:59, 45.47it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  46%|####6     | 2304/5000 [00:48&lt;01:04, 41.57it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  47%|####6     | 2336/5000 [00:48&lt;01:01, 43.58it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  47%|####7     | 2368/5000 [00:49&lt;00:58, 45.35it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  48%|####8     | 2400/5000 [00:50&lt;00:54, 47.73it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  49%|####8     | 2432/5000 [00:50&lt;00:52, 48.46it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  49%|####9     | 2464/5000 [00:51&lt;00:50, 49.82it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  50%|####9     | 2496/5000 [00:51&lt;00:49, 50.66it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  51%|#####     | 2528/5000 [00:52&lt;00:48, 50.64it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  51%|#####1    | 2560/5000 [00:53&lt;00:47, 51.54it/s]

error:  0.3903, value:  1.9619, test return:  3.5000:  52%|#####1    | 2592/5000 [00:53&lt;00:46, 51.27it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  52%|#####1    | 2592/5000 [00:55&lt;00:46, 51.27it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  52%|#####2    | 2624/5000 [00:55&lt;00:59, 40.16it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  53%|#####3    | 2656/5000 [00:55&lt;00:55, 42.31it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  54%|#####3    | 2688/5000 [00:56&lt;00:56, 40.94it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  54%|#####4    | 2720/5000 [00:57&lt;00:52, 43.05it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  55%|#####5    | 2752/5000 [00:57&lt;00:49, 45.52it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  56%|#####5    | 2784/5000 [00:58&lt;00:46, 47.16it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  56%|#####6    | 2816/5000 [00:59&lt;00:45, 48.25it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  57%|#####6    | 2848/5000 [00:59&lt;00:43, 50.04it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  58%|#####7    | 2880/5000 [01:00&lt;00:42, 50.29it/s]

error:  0.9443, value:  1.8942, test return:  5.8000:  58%|#####8    | 2912/5000 [01:00&lt;00:41, 50.84it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  58%|#####8    | 2912/5000 [01:01&lt;00:41, 50.84it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  59%|#####8    | 2944/5000 [01:01&lt;00:43, 46.79it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  60%|#####9    | 2976/5000 [01:02&lt;00:42, 47.14it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  60%|######    | 3008/5000 [01:03&lt;00:42, 46.95it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  61%|######    | 3040/5000 [01:03&lt;00:40, 47.87it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  61%|######1   | 3072/5000 [01:04&lt;00:40, 47.21it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  62%|######2   | 3104/5000 [01:05&lt;00:42, 45.04it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  63%|######2   | 3136/5000 [01:05&lt;00:41, 44.95it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  63%|######3   | 3168/5000 [01:06&lt;00:40, 45.17it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  64%|######4   | 3200/5000 [01:07&lt;00:38, 46.58it/s]

error:  0.5951, value:  1.5737, test return:  2.2000:  65%|######4   | 3232/5000 [01:07&lt;00:36, 47.98it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  65%|######4   | 3232/5000 [01:08&lt;00:36, 47.98it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  65%|######5   | 3264/5000 [01:08&lt;00:42, 40.86it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  66%|######5   | 3296/5000 [01:09&lt;00:38, 44.20it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  67%|######6   | 3328/5000 [01:10&lt;00:35, 46.65it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  67%|######7   | 3360/5000 [01:10&lt;00:34, 48.12it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  68%|######7   | 3392/5000 [01:11&lt;00:33, 48.45it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  68%|######8   | 3424/5000 [01:11&lt;00:31, 49.49it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  69%|######9   | 3456/5000 [01:12&lt;00:31, 49.72it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  70%|######9   | 3488/5000 [01:13&lt;00:29, 50.91it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  70%|#######   | 3520/5000 [01:13&lt;00:29, 50.67it/s]

error:  0.2477, value:  1.3986, test return:  4.6000:  71%|#######1  | 3552/5000 [01:14&lt;00:29, 48.70it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  71%|#######1  | 3552/5000 [01:15&lt;00:29, 48.70it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  72%|#######1  | 3584/5000 [01:15&lt;00:31, 44.49it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  72%|#######2  | 3616/5000 [01:16&lt;00:30, 44.76it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  73%|#######2  | 3648/5000 [01:16&lt;00:29, 45.97it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  74%|#######3  | 3680/5000 [01:17&lt;00:27, 47.15it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  74%|#######4  | 3712/5000 [01:18&lt;00:27, 47.67it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  75%|#######4  | 3744/5000 [01:18&lt;00:25, 49.31it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  76%|#######5  | 3776/5000 [01:19&lt;00:24, 49.80it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  76%|#######6  | 3808/5000 [01:19&lt;00:24, 49.29it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  77%|#######6  | 3840/5000 [01:20&lt;00:23, 50.11it/s]

error:  1.1071, value:  2.8851, test return:  2.0000:  77%|#######7  | 3872/5000 [01:21&lt;00:22, 51.03it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  77%|#######7  | 3872/5000 [01:21&lt;00:22, 51.03it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  78%|#######8  | 3904/5000 [01:21&lt;00:22, 49.24it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  79%|#######8  | 3936/5000 [01:22&lt;00:21, 50.53it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  79%|#######9  | 3968/5000 [01:23&lt;00:20, 51.11it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  80%|########  | 4000/5000 [01:23&lt;00:19, 51.57it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  81%|########  | 4032/5000 [01:24&lt;00:19, 50.59it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  81%|########1 | 4064/5000 [01:25&lt;00:19, 49.13it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  82%|########1 | 4096/5000 [01:25&lt;00:19, 47.23it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  83%|########2 | 4128/5000 [01:26&lt;00:18, 47.59it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  83%|########3 | 4160/5000 [01:27&lt;00:17, 48.23it/s]

error:  0.2238, value:  1.1325, test return:  0.9000:  84%|########3 | 4192/5000 [01:27&lt;00:16, 49.25it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  84%|########3 | 4192/5000 [01:28&lt;00:16, 49.25it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  84%|########4 | 4224/5000 [01:28&lt;00:16, 47.85it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  85%|########5 | 4256/5000 [01:29&lt;00:15, 48.80it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  86%|########5 | 4288/5000 [01:29&lt;00:14, 49.98it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  86%|########6 | 4320/5000 [01:30&lt;00:13, 50.02it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  87%|########7 | 4352/5000 [01:30&lt;00:13, 49.40it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  88%|########7 | 4384/5000 [01:31&lt;00:12, 49.95it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  88%|########8 | 4416/5000 [01:32&lt;00:11, 50.54it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  89%|########8 | 4448/5000 [01:32&lt;00:10, 50.46it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  90%|########9 | 4480/5000 [01:33&lt;00:10, 50.70it/s]

error:  0.4595, value:  1.5100, test return:  0.9000:  90%|######### | 4512/5000 [01:34&lt;00:10, 48.76it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  90%|######### | 4512/5000 [01:35&lt;00:10, 48.76it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  91%|######### | 4544/5000 [01:35&lt;00:11, 40.73it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  92%|#########1| 4576/5000 [01:35&lt;00:10, 41.66it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  92%|#########2| 4608/5000 [01:36&lt;00:09, 43.14it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  93%|#########2| 4640/5000 [01:37&lt;00:08, 44.61it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  93%|#########3| 4672/5000 [01:37&lt;00:07, 46.65it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  94%|#########4| 4704/5000 [01:38&lt;00:06, 47.94it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  95%|#########4| 4736/5000 [01:39&lt;00:05, 48.43it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  95%|#########5| 4768/5000 [01:39&lt;00:04, 49.16it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  96%|#########6| 4800/5000 [01:40&lt;00:03, 50.14it/s]

error:  0.5285, value:  0.5095, test return:  3.5000:  97%|#########6| 4832/5000 [01:41&lt;00:03, 50.40it/s]

error:  0.5001, value:  1.8679, test return:  1.1000:  97%|#########6| 4832/5000 [01:41&lt;00:03, 50.40it/s]

error:  0.5001, value:  1.8679, test return:  1.1000:  97%|#########7| 4864/5000 [01:41&lt;00:02, 48.50it/s]

error:  0.5001, value:  1.8679, test return:  1.1000:  98%|#########7| 4896/5000 [01:42&lt;00:02, 49.31it/s]

error:  0.5001, value:  1.8679, test return:  1.1000:  99%|#########8| 4928/5000 [01:43&lt;00:01, 49.79it/s]

error:  0.5001, value:  1.8679, test return:  1.1000:  99%|#########9| 4960/5000 [01:43&lt;00:00, 50.66it/s]

error:  0.5001, value:  1.8679, test return:  1.1000: 100%|#########9| 4992/5000 [01:44&lt;00:00, 50.46it/s]

error:  0.5001, value:  1.8679, test return:  1.1000: : 5024it [01:45, 48.46it/s]
</pre></div>
</div>
<p>TD(<span class="math notranslate nohighlight">\(\lambda\)</span>) performs significantly better than TD(0) because it
retrieves a much less biased estimate of the state-action value.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">logs_exp2</span><span class="p">,</span> <span class="s2">&quot;dqn_tdlambda.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="Cart Pole results with TD(lambda)" src="../_images/dqn_tdlambda.png" />
</figure>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shutting down&quot;</span><span class="p">)</span>
<span class="n">data_collector</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
<span class="k">del</span> <span class="n">data_collector</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>shutting down
</pre></div>
</div>
<p>Let’s compare the results on a single plot. Because the TD(lambda) version
works better, we’ll have fewer episodes collected for a given number of
frames (as there are more frames per episode).</p>
<p><strong>Note</strong>: As already mentioned above, to get a more reasonable performance,
use a greater value for <code class="docutils literal notranslate"><span class="pre">total_frames</span></code> e.g. 500000.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_both</span><span class="p">():</span>
    <span class="n">frames_td0</span> <span class="o">=</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
    <span class="n">frames_tdlambda</span> <span class="o">=</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;frames&quot;</span><span class="p">]</span>
    <span class="n">evals_td0</span> <span class="o">=</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span>
    <span class="n">evals_tdlambda</span> <span class="o">=</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;evals&quot;</span><span class="p">]</span>
    <span class="n">mavgs_td0</span> <span class="o">=</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span>
    <span class="n">mavgs_tdlambda</span> <span class="o">=</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;mavgs&quot;</span><span class="p">]</span>
    <span class="n">traj_count_td0</span> <span class="o">=</span> <span class="n">logs_exp1</span><span class="p">[</span><span class="s2">&quot;traj_count_eval&quot;</span><span class="p">]</span>
    <span class="n">traj_count_tdlambda</span> <span class="o">=</span> <span class="n">logs_exp2</span><span class="p">[</span><span class="s2">&quot;traj_count_eval&quot;</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">evals_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td0)&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">frames_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
        <span class="n">evals_tdlambda</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td(lambda))&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">frames_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td0)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">frames_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
        <span class="n">mavgs_tdlambda</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td(lambda))&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;frames collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;trajectory length (= return)&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">traj_count_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_td0</span><span class="p">)</span> <span class="p">:],</span>
        <span class="n">evals_td0</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td0)&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">traj_count_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">evals_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
        <span class="n">evals_tdlambda</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;return (td(lambda))&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj_count_td0</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_td0</span><span class="p">)</span> <span class="p">:],</span> <span class="n">mavgs_td0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td0)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">traj_count_tdlambda</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mavgs_tdlambda</span><span class="p">)</span> <span class="p">:],</span>
        <span class="n">mavgs_tdlambda</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mavg (td(lambda))&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;trajectories collected&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;dqn.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_both</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="Cart Pole results from the TD(:math:`lambda`) trained policy." src="../_images/dqn.png" />
</figure>
<p>Finally, we generate a new video to check what the algorithm has learnt.
If all goes well, the duration should be significantly longer than with a
random rollout.</p>
<p>To get the raw pixels of the rollout, we insert a
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.envs.CatTensors</span></code> transform that precedes all others and copies
the <code class="docutils literal notranslate"><span class="pre">&quot;pixels&quot;</span></code> key onto a <code class="docutils literal notranslate"><span class="pre">&quot;pixels_save&quot;</span></code> key. This is necessary because
the other transforms that modify this key will update its value in-place in
the output tensordict.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_env</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <a href="https://pytorch.org/rl/reference/generated/torchrl.envs.transforms.CatTensors.html#torchrl.envs.transforms.CatTensors" title="torchrl.envs.transforms.transforms.CatTensors" class="sphx-glr-backref-module-torchrl-envs-transforms-transforms sphx-glr-backref-type-py-class"><span class="n">CatTensors</span></a><span class="p">([</span><span class="s2">&quot;pixels&quot;</span><span class="p">],</span> <span class="s2">&quot;pixels_save&quot;</span><span class="p">,</span> <span class="n">del_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a> <span class="o">=</span> <span class="n">test_env</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><a href="https://pytorch.org/rl/reference/generated/torchrl.modules.tensordict_module.QValueActor.html#torchrl.modules.tensordict_module.QValueActor" title="torchrl.modules.tensordict_module.actors.QValueActor" class="sphx-glr-backref-module-torchrl-modules-tensordict_module-actors sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">actor</span></a><span class="p">,</span> <span class="n">auto_reset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>


<span class="k">del</span> <span class="n">test_env</span>
</pre></div>
</div>
<p>The video of the rollout can be saved using the imageio package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imageio</span>
<span class="n">imageio</span><span class="o">.</span><span class="n">mimwrite</span><span class="p">(</span><span class="s1">&#39;cartpole.mp4&#39;</span><span class="p">,</span> <a href="https://pytorch-labs.github.io/tensordict/reference/generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict" class="sphx-glr-backref-module-tensordict sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eval_rollout</span></a><span class="p">[</span><span class="s2">&quot;pixels_save&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">);</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="Cart Pole results from the TD(:math:`\lambda`) trained policy." src="../_images/cartpole.gif" />
</figure>
</section>
<section id="conclusion-and-possible-improvements">
<h2>Conclusion and possible improvements<a class="headerlink" href="#conclusion-and-possible-improvements" title="Permalink to this heading">¶</a></h2>
<p>In this tutorial we have learnt:</p>
<ul class="simple">
<li><p>How to train a policy that read pixel-based states, what transforms to
include and how to normalize the data;</p></li>
<li><p>How to create a policy that picks up the action with the highest value
with <code class="xref py py-class docutils literal notranslate"><span class="pre">torchrl.modules.QValueNetwork</span></code>;</p></li>
<li><p>How to build a multiprocessed data collector;</p></li>
<li><p>How to train a DQN with TD(<span class="math notranslate nohighlight">\(\lambda\)</span>) returns.</p></li>
</ul>
<p>We have seen that using TD(<span class="math notranslate nohighlight">\(\lambda\)</span>) greatly improved the performance
of DQN. Other possible improvements could include:</p>
<ul>
<li><p>Using the Multi-Step post-processing. Multi-step will project an action
to the nth following step, and create a discounted sum of the rewards in
between. This trick can make the algorithm noticebly less myopic. To use
this, simply create the collector with</p>
<blockquote>
<div><p>from torchrl.data.postprocs.postprocs import MultiStep
collector = CollectorClass(…, postproc=MultiStep(gamma, n))</p>
</div></blockquote>
<p>where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of looking-forward steps. Pay attention to the
fact that the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> factor has to be corrected by the number of
steps till the next observation when being passed to
<code class="docutils literal notranslate"><span class="pre">vec_td_lambda_advantage_estimate</span></code>:</p>
<blockquote>
<div><p>gamma = gamma ** tensordict[“steps_to_next_obs”]</p>
</div></blockquote>
</li>
<li><p>A prioritized replay buffer could also be used. This will give a
higher priority to samples that have the worst value accuracy.</p></li>
<li><p>A distributional loss (see <code class="docutils literal notranslate"><span class="pre">torchrl.objectives.DistributionalDQNLoss</span></code>
for more information).</p></li>
<li><p>More fancy exploration techniques, such as NoisyLinear layers and such
(check <code class="docutils literal notranslate"><span class="pre">torchrl.modules.NoisyLinear</span></code>, which is fully compatible with the
<code class="docutils literal notranslate"><span class="pre">MLP</span></code> class used in our Dueling DQN).</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 5 minutes  10.890 seconds)</p>
<p><strong>Estimated memory usage:</strong>  1536 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-coding-dqn-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/be66e8850a06844c91f6264538ad69e8/coding_dqn.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">coding_dqn.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/25730743bad2ad4374b1a37c2e8d077a/coding_dqn.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">coding_dqn.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../reference/index.html" class="btn btn-neutral float-right" title="API Reference" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="coding_ddpg.html" class="btn btn-neutral" title="Coding DDPG using TorchRL" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Coding a pixel-based DQN using TorchRL</a><ul>
<li><a class="reference internal" href="#hyperparameters">Hyperparameters</a><ul>
<li><a class="reference internal" href="#optimizer">Optimizer</a></li>
<li><a class="reference internal" href="#dqn-parameters">DQN parameters</a></li>
<li><a class="reference internal" href="#data-collection-and-replay-buffer">Data collection and replay buffer</a></li>
<li><a class="reference internal" href="#environment-and-exploration">Environment and exploration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-the-environment">Building the environment</a><ul>
<li><a class="reference internal" href="#compute-normalizing-constants">Compute normalizing constants</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-the-model-deep-q-network">Building the model (Deep Q-network)</a><ul>
<li><a class="reference internal" href="#target-parameters">Target parameters</a></li>
<li><a class="reference internal" href="#functionalizing-modules">Functionalizing modules</a></li>
</ul>
</li>
<li><a class="reference internal" href="#collecting-and-storing-data">Collecting and storing data</a><ul>
<li><a class="reference internal" href="#replay-buffers">Replay buffers</a></li>
<li><a class="reference internal" href="#data-collector">Data collector</a></li>
</ul>
</li>
<li><a class="reference internal" href="#training-loop-of-a-regular-dqn">Training loop of a regular DQN</a></li>
<li><a class="reference internal" href="#dqn-with-td-lambda">DQN with TD(<span class="math notranslate nohighlight">\(\lambda\)</span>)</a></li>
<li><a class="reference internal" href="#data-replay-buffer-and-collector">Data: Replay buffer and collector</a></li>
<li><a class="reference internal" href="#training-loop">Training loop</a></li>
<li><a class="reference internal" href="#conclusion-and-possible-improvements">Conclusion and possible improvements</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/sphinx_highlight.js"></script>
         <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>