


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchrl.data.tensordict.tensordict &mdash; torchrl main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../reference/index.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>torchrl.data.tensordict.tensordict</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torchrl.data.tensordict.tensordict</h1><div class="highlight"><pre>
<span></span><span class="c1"># pad_size, value Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">textwrap</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Mapping</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span><span class="p">,</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>
<span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">indent</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generator</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">KeysView</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.jit._shape_functions</span> <span class="kn">import</span> <span class="n">infer_size_impl</span>

<span class="c1"># from torch.utils._pytree import _register_pytree_node</span>

<span class="kn">from</span> <span class="nn">torchrl._utils</span> <span class="kn">import</span> <span class="n">KeyDependentDefaultDict</span><span class="p">,</span> <span class="n">prod</span>
<span class="kn">from</span> <span class="nn">torchrl.data.tensordict.memmap</span> <span class="kn">import</span> <span class="n">MemmapTensor</span>
<span class="kn">from</span> <span class="nn">torchrl.data.tensordict.metatensor</span> <span class="kn">import</span> <span class="n">MetaTensor</span>
<span class="kn">from</span> <span class="nn">torchrl.data.tensordict.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_getitem_batch_size</span><span class="p">,</span>
    <span class="n">_sub_index</span><span class="p">,</span>
    <span class="n">convert_ellipsis_to_idx</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchrl.data.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DEVICE_TYPING</span><span class="p">,</span>
    <span class="n">expand_right</span><span class="p">,</span>
    <span class="n">expand_as_right</span><span class="p">,</span>
    <span class="n">INDEX_TYPING</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">_has_functorch</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">functorch._C</span> <span class="kn">import</span> <span class="n">is_batchedtensor</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">torch._C._functorch</span> <span class="kn">import</span> <span class="n">is_batchedtensor</span>

    <span class="n">_has_functorch</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">_has_functorch</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;TensorDict&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SubTensorDict&quot;</span><span class="p">,</span>
    <span class="s2">&quot;merge_tensordicts&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LazyStackedTensorDict&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SavedTensorDict&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">TD_HANDLED_FUNCTIONS</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">COMPATIBLE_TYPES</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">MemmapTensor</span><span class="p">,</span>
<span class="p">]</span>  <span class="c1"># None? # leaves space for TensorDictBase</span>

<span class="n">_STR_MIXED_INDEX_ERROR</span> <span class="o">=</span> <span class="s2">&quot;Received a mixed string-non string index. Only string-only or string-free indices are supported.&quot;</span>


<span class="k">class</span> <span class="nc">TensorDictBase</span><span class="p">(</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">abc</span><span class="o">.</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TensorDictBase is an abstract parent class for TensorDicts, the torchrl</span>
<span class="sd">    data container.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_safe</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_lazy</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_inplace_set</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">is_meta</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_dict_meta&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_dict_meta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">KeyDependentDefaultDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_make_meta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span> <span class="o">=</span> <span class="n">KeyDependentDefaultDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_make_meta</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;See TensorDictBase.batch_size&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Shape of (or batch_size) of a TensorDict.</span>
<span class="sd">        The shape of a tensordict corresponds to the common N first</span>
<span class="sd">        dimensions of the tensors it contains, where N is an arbitrary</span>
<span class="sd">        number. The TensorDict shape is controlled by the user upon</span>
<span class="sd">        initialization (i.e. it is not inferred from the tensor shapes) and</span>
<span class="sd">        it should not be changed dynamically.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a torch.Size object describing the TensorDict batch size.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the size of the dimension indicated by `dim`. If dim is not</span>
<span class="sd">        specified, returns the batch_size (or shape) of the TensorDict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_batch_size_setter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">new_batch_size</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;modifying the batch size of a lazy repesentation of a &quot;</span>
                <span class="s2">&quot;tensordict is not permitted. Consider instantiating the &quot;</span>
                <span class="s2">&quot;tensordict fist by calling `td = td.to_tensordict()` before &quot;</span>
                <span class="s2">&quot;resetting the batch size.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="n">new_batch_size</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_batch_size</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">new_batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">new_batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_new_batch_size</span><span class="p">(</span><span class="n">new_batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_change_batch_size</span><span class="p">(</span><span class="n">new_batch_size</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Length of the tensordict batch size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int describing the number of dimensions of the tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ndimension</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span>

    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Device of a TensorDict. If the TensorDict has a specified device, all</span>
<span class="sd">        tensors of a tensordict must live on the same device. If the TensorDict device</span>
<span class="sd">        is None, then different values can be located on different devices.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.device object indicating the device where the tensors</span>
<span class="sd">            are placed, or None if TensorDict does not have a device.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">clear_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Checks if tensordict is in shared memory.</span>

<span class="sd">        This is always True for CUDA tensordicts, except when stored as</span>
<span class="sd">        MemmapTensors.</span>

<span class="sd">        Args:</span>
<span class="sd">            no_check (bool, optional): whether to use cached value or not</span>
<span class="sd">                Default is True</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">_is_shared</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="n">_is_shared</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">is_memmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Checks if tensordict is stored with MemmapTensors.</span>

<span class="sd">        Args:</span>
<span class="sd">            no_check (bool, optional): whether to use cached value or not</span>
<span class="sd">                Default is True</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">_is_memmap</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="n">_is_memmap</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">numel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Total number of elements in the batch.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_check_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;batch_size are incongruent, got </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;-- expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets a new key-value pair.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): name of the value</span>
<span class="sd">            item (torch.Tensor): value to be stored in the tensordict</span>
<span class="sd">            inplace (bool, optional): if True and if a key matches an existing</span>
<span class="sd">                key in the tensordict, then the update will occur in-place</span>
<span class="sd">                for that key-value pair. Default is `False`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets a value to an existing key while keeping the original storage.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): name of the value</span>
<span class="sd">            item (torch.Tensor): value to be stored in the tensordict</span>
<span class="sd">            no_check (bool, optional): if True, it is assumed that device and shape</span>
<span class="sd">                match the original tensor and that the keys is in the tensordict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Stacks a list of values onto an existing key while keeping the original storage.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): name of the value</span>
<span class="sd">            list_item (list of torch.Tensor): value to be stacked and stored in the tensordict.</span>
<span class="sd">            dim (int): dimension along which the tensors should be stacked.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_stack_onto_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Similar to _stack_onto_ but on a specific index. Only works with regular TensorDicts.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Cannot call _stack_onto_at_ with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="s2">&quot;This error is probably caused by a call to a lazy operation before stacking. &quot;</span>
            <span class="s2">&quot;Make sure your sub-classed tensordicts are turned into regular tensordicts by calling to_tensordict() &quot;</span>
            <span class="s2">&quot;before calling __getindex__ and stack.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_default_get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">default</span>
        <span class="k">if</span> <span class="n">default</span> <span class="o">==</span> <span class="s2">&quot;_no_default_&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;key &quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot; not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1"> with &#39;</span>
                <span class="sa">f</span><span class="s2">&quot;keys </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;default should be None or a Tensor instance, &quot;</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">default</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value stored with the input key.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): key to be queried.</span>
<span class="sd">            default: default value if the key is not found in the tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected key to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> with keys&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Applies a callable to all values stored in the tensordict and</span>
<span class="sd">        re-writes them in-place.</span>

<span class="sd">        Args:</span>
<span class="sd">            fn (Callable): function to be applied to the tensors in the</span>
<span class="sd">                tensordict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self or a copy of self with the function applied</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Applies a callable to all values stored in the tensordict and sets</span>
<span class="sd">        them in a new tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            fn (Callable): function to be applied to the tensors in the</span>
<span class="sd">                tensordict.</span>
<span class="sd">            batch_size (sequence of int, optional): if provided,</span>
<span class="sd">                the resulting TensorDict will have the desired batch_size.</span>
<span class="sd">                The `batch_size` argument should match the batch_size after</span>
<span class="sd">                the transformation.</span>
<span class="sd">            inplace (bool, optional): if True, changes are made in-place.</span>
<span class="sd">                Default is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict with transformed_in tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span>
            <span class="k">if</span> <span class="n">inplace</span>
            <span class="k">else</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="n">item_trsf</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">item_trsf</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">item_trsf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item_trsf</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Updates the TensorDict with values from either a dictionary or</span>
<span class="sd">            another TensorDict.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_dict_or_td (TensorDictBase or dict): Does not keyword arguments</span>
<span class="sd">                (unlike `dict.update()`).</span>
<span class="sd">            clone (bool, optional): whether the tensors in the input (</span>
<span class="sd">                tensor) dict should be cloned before being set. Default is</span>
<span class="sd">                `False`.</span>
<span class="sd">            inplace (bool, optional): if True and if a key matches an existing</span>
<span class="sd">                key in the tensordict, then the update will occur in-place</span>
<span class="sd">                for that key-value pair. Default is `False`.</span>
<span class="sd">            **kwargs: keyword arguments for the `TensorDict.set` method</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="c1"># no op</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">update_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Updates the TensorDict in-place with values from either a dictionary</span>
<span class="sd">        or another TensorDict.</span>

<span class="sd">        Unlike TensorDict.update, this function will</span>
<span class="sd">        throw an error if the key is unknown to the TensorDict</span>

<span class="sd">        Args:</span>
<span class="sd">            input_dict_or_td (TensorDictBase or dict): Does not keyword</span>
<span class="sd">                arguments (unlike `dict.update()`).</span>
<span class="sd">            clone (bool, optional): whether the tensors in the input (</span>
<span class="sd">                tensor) dict should be cloned before being set. Default is</span>
<span class="sd">                `False`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="c1"># no op</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">update_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Updates the TensorDict in-place at the specified index with</span>
<span class="sd">        values from either a dictionary or another TensorDict.</span>

<span class="sd">        Unlike  TensorDict.update, this function will throw an error if the</span>
<span class="sd">        key is unknown to the TensorDict.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_dict_or_td (TensorDictBase or dict): Does not keyword arguments</span>
<span class="sd">                (unlike `dict.update()`).</span>
<span class="sd">            idx (int, torch.Tensor, iterable, slice): index of the tensordict</span>
<span class="sd">                where the update should occur.</span>
<span class="sd">            clone (bool, optional): whether the tensors in the input (</span>
<span class="sd">                tensor) dict should be cloned before being set. Default is</span>
<span class="sd">                `False`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3, 4, 5),</span>
<span class="sd">            ...    &#39;b&#39;: torch.zeros(3, 4, 10)}, batch_size=[3, 4])</span>
<span class="sd">            &gt;&gt;&gt; td.update_at_(</span>
<span class="sd">            ...    TensorDict(source={&#39;a&#39;: torch.ones(1, 4, 5),</span>
<span class="sd">            ...        &#39;b&#39;: torch.ones(1, 4, 10)}, batch_size=[1, 4]),</span>
<span class="sd">            ...    slice(1, 2))</span>
<span class="sd">            TensorDict(</span>
<span class="sd">                fields={a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32),</span>
<span class="sd">                    b: Tensor(torch.Size([3, 4, 10]),\</span>
<span class="sd">dtype=torch.float32)},</span>
<span class="sd">                shared=False,</span>
<span class="sd">                batch_size=torch.Size([3, 4]),</span>
<span class="sd">                device=cpu)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">idx</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_convert_to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_convert_to_tensordict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dict_value</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">dict_value</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_input</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">check_device</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">check_tensor_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">check_shared</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">]:</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_to_tensordict</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="c1"># if (</span>
        <span class="c1">#     _has_functorch and isinstance(tensor, Tensor) and is_batchedtensor(tensor)</span>
        <span class="c1"># ):  # TODO: find a proper way of doing that</span>
        <span class="c1">#     return tensor</span>
        <span class="c1">#     tensor = _unwrap_value(tensor)[0]</span>

        <span class="k">if</span> <span class="n">check_device</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">check_shared</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span><span class="s2">&quot;check_shared is not authorized anymore&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">check_tensor_shape</span> <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="c1"># if TensorDict, let&#39;s try to map it to the desired shape</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="p">):</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;batch dimension mismatch, got self.batch_size&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> and tensor.shape[:self.batch_dims]&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2"> with tensor </span><span class="si">{</span><span class="n">tensor</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="c1"># minimum ndimension is 1</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span>
        <span class="p">):</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tensor</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Calls pin_memory() on the stored tensors.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># @abc.abstractmethod</span>
    <span class="c1"># def is_pinned(self) -&gt; bool:</span>
    <span class="c1">#     &quot;&quot;&quot;Checks if tensors are pinned.&quot;&quot;&quot;</span>
    <span class="c1">#     raise NotImplementedError(f&quot;{self.__class__.__name__}&quot;)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a generator of key-value pairs for the tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a generator representing the values for the tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_unset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">MetaTensor</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a generator of key-value pairs for the tensordict, where the</span>
<span class="sd">        values are MetaTensor instances corresponding to the stored tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">make_unset</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">yield</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">values_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">make_unset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">MetaTensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a generator representing the values for the tensordict, those</span>
<span class="sd">        values are MetaTensor instances corresponding to the stored tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">make_unset</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KeysView</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a generator of tensordict keys.&quot;&quot;&quot;</span>

        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Expands each tensors of the tensordict according to</span>
<span class="sd">        `tensor.expand(*shape, *tensor.shape)`</span>
<span class="sd">        Supports iterables to specify the shape</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3, 4, 5),</span>
<span class="sd">            ...     &#39;b&#39;: torch.zeros(3, 4, 10)}, batch_size=[3, 4])</span>
<span class="sd">            &gt;&gt;&gt; td_expand = td.expand(10, 3, 4)</span>
<span class="sd">            &gt;&gt;&gt; assert td_expand.shape == torch.Size([10, 3, 4])</span>
<span class="sd">            &gt;&gt;&gt; assert td_expand.get(&quot;a&quot;).shape == torch.Size([10, 3, 4, 5])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">tensordict_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># new shape dim check</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;the number of sizes provided (</span><span class="si">{shape_dim}</span><span class="s2">) must be greater or equal to the number of &quot;</span>
                <span class="s2">&quot;dimensions in the TensorDict (</span><span class="si">{tensordict_dim}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">shape_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">tensordict_dim</span><span class="o">=</span><span class="n">tensordict_dims</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># new shape compatability check</span>
        <span class="k">for</span> <span class="n">old_dim</span><span class="p">,</span> <span class="n">new_dim</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="n">tensordict_dims</span><span class="p">:]):</span>
            <span class="k">if</span> <span class="n">old_dim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">new_dim</span> <span class="o">!=</span> <span class="n">old_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Incompatible expanded shape: The expanded shape length at non-singleton dimension should be same &quot;</span>
                    <span class="s2">&quot;as the original length. target_shape = </span><span class="si">{new_shape}</span><span class="s2">, existing_shape = </span><span class="si">{old_shape}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">new_shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">old_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="p">)</span>
                <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensor_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">last_n_dims</span> <span class="o">=</span> <span class="n">tensor_dims</span> <span class="o">-</span> <span class="n">tensordict_dims</span>
                <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="n">last_n_dims</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="n">shape</span><span class="p">],</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Converting a tensordict to boolean value is not permitted&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__ne__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;XOR operation over two tensordicts, for evey key. The two</span>
<span class="sd">        tensordicts must have the same key set.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new TensorDict instance with all tensors are boolean</span>
<span class="sd">            tensors of the same shape as the original tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">other</span> <span class="o">=</span> <span class="n">make_tensordict</span><span class="p">(</span><span class="o">**</span><span class="n">other</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">other</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">keys1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">keys2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys1</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">keys2</span><span class="p">))</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys1</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys2</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;keys in </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">other</span><span class="si">}</span><span class="s2"> mismatch, got </span><span class="si">{</span><span class="n">keys1</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">keys2</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item1</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">item1</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compares two tensordicts against each other, for every key. The two</span>
<span class="sd">        tensordicts must have the same key set.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new TensorDict instance with all tensors are boolean</span>
<span class="sd">            tensors of the same shape as the original tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">other</span> <span class="o">=</span> <span class="n">make_tensordict</span><span class="p">(</span><span class="o">**</span><span class="n">other</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="o">==</span> <span class="n">other</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">keys1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">keys2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys1</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">keys2</span><span class="p">))</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys1</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys2</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;keys in tensordicts mismatch, got </span><span class="si">{</span><span class="n">keys1</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">keys2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item1</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">item1</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deletes a key of the tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): key to be deleted</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Selects the keys of the tensordict and returns an new tensordict</span>
<span class="sd">        with only the selected keys.</span>

<span class="sd">        The values are not copied: in-place modifications a tensor of either</span>
<span class="sd">        of the original or new tensordict will result in a change in both</span>
<span class="sd">        tensordicts.</span>

<span class="sd">        Args:</span>
<span class="sd">            *keys (str): keys to select</span>
<span class="sd">            inplace (bool): if True, the tensordict is pruned in place.</span>
<span class="sd">                Default is `False`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new tensordict with the selected keys only.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">exclude</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets the values in-place at the index indicated by `idx`.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): key to be modified.</span>
<span class="sd">            value (torch.Tensor): value to be set at the index `idx`</span>
<span class="sd">            idx (int, tensor or tuple): index where to write the values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">copy_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;See `TensorDictBase.update_`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">copy_at_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;See `TensorDictBase.update_at_`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_at</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the value of a tensordict from the key `key` at the index `idx`.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): key to be retrieved.</span>
<span class="sd">            idx (int, slice, torch.Tensor, iterable): index of the tensor.</span>
<span class="sd">            default (torch.Tensor): default value to return if the key is</span>
<span class="sd">                not present in the tensordict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            indexed tensor.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">default</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">value</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Places all the tensors in shared memory.</span>

<span class="sd">        Args:</span>
<span class="sd">            lock (bool): prevents changes to the dictionary except for inplace overwrites to existing keys</span>

<span class="sd">        Returns:</span>
<span class="sd">            self.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Writes all tensors onto a MemmapTensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            prefix (str): directory prefix where the memmap tensors will have to</span>
<span class="sd">                be stored.</span>
<span class="sd">            lock (bool): prevents changes to the dictionary except for inplace overwrites to existing keys</span>

<span class="sd">        Returns:</span>
<span class="sd">            self.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Detach the tensors in the tensordict in-place.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">detach</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Detach the tensors in the tensordict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict with no tensor requiring gradient.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">item</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_tensordict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a regular TensorDict instance from the TensorDictBase.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new TensorDict object containing the same values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">value</span><span class="o">.</span><span class="n">to_tensordict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">zero_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Zeros all tensors in the tensordict in-place.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">unbind</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a tuple of indexed tensordicts unbound along the</span>
<span class="sd">        indicated dimension. Resulting tensordicts will share</span>
<span class="sd">        the storage of the initial tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="p">,))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Attempts to split a tendordict into the specified number of</span>
<span class="sd">        chunks. Each chunk is a view of the input tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            chunks (int): number of chunks to return</span>
<span class="sd">            dim (int, optional): dimension along which to split the</span>
<span class="sd">                tensordict. Default is 0.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">chunks</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;chunks must be a strictly positive integer, got </span><span class="si">{</span><span class="n">chunks</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">_idx_start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">chunks</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">interval</span> <span class="o">=</span> <span class="n">_idx_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">//</span> <span class="n">chunks</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">interval</span> <span class="o">=</span> <span class="n">_idx_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
            <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">_idx_start</span><span class="p">,</span> <span class="n">_idx_end</span><span class="p">))</span>
            <span class="n">_idx_start</span> <span class="o">=</span> <span class="n">_idx_end</span>
            <span class="k">if</span> <span class="n">c</span> <span class="o">&lt;</span> <span class="n">chunks</span> <span class="o">-</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">_idx_end</span> <span class="o">=</span> <span class="n">_idx_end</span> <span class="o">+</span> <span class="n">interval</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_idx_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">[(</span><span class="o">*</span><span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">)],</span> <span class="n">idx</span><span class="p">)]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">recurse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Clones a TensorDictBase subclass instance onto a new TensorDict.</span>

<span class="sd">        Args:</span>
<span class="sd">            recurse (bool, optional): if True, each tensor contained in the</span>
<span class="sd">                TensorDict will be copied too. Default is `True`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">recurse</span> <span class="k">else</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">__torch_function__</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">types</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">TD_HANDLED_FUNCTIONS</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">issubclass</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">))</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">types</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="bp">NotImplemented</span>
        <span class="k">return</span> <span class="n">TD_HANDLED_FUNCTIONS</span><span class="p">[</span><span class="n">func</span><span class="p">](</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Maps a TensorDictBase subclass either on a new device or to another</span>
<span class="sd">        TensorDictBase subclass (if permitted). Casting tensors to a new dtype</span>
<span class="sd">        is not allowed, as tensordicts are not bound to contain a single</span>
<span class="sd">        tensor dtype.</span>

<span class="sd">        Args:</span>
<span class="sd">            dest (device, size or TensorDictBase subclass): destination of the</span>
<span class="sd">                tensordict. If it is a torch.Size object, the batch_size</span>
<span class="sd">                will be updated provided that it is compatible with the</span>
<span class="sd">                stored tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict. If device indicated by dest differs from</span>
<span class="sd">            the tensordict device, this is a no-op.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_check_new_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">meta_tensor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">meta_tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">meta_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span> <span class="o">!=</span> <span class="n">new_size</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;TensorDict requires tensors that have at least one more &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;dimension than the batch_size. The tensor &quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot; has shape &#39;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">meta_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> which is the same as the new size.&quot;</span>
                    <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;the tensor </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> has shape </span><span class="si">{</span><span class="n">meta_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> which &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is incompatible with the new shape </span><span class="si">{</span><span class="n">new_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Casts a tensordict to cpu (if not already on cpu).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Casts a tensordict to a cuda device (if not already on it).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Fills the values corresponding to the mask with the desired value.</span>

<span class="sd">        Args:</span>
<span class="sd">            mask (boolean torch.Tensor): mask of values to be filled. Shape</span>
<span class="sd">                must match tensordict shape.</span>
<span class="sd">            value: value to used to fill the tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3, 4)},</span>
<span class="sd">            ...     batch_size=[3])</span>
<span class="sd">            &gt;&gt;&gt; mask = torch.tensor([True, False, False])</span>
<span class="sd">            &gt;&gt;&gt; _ = td.masked_fill_(mask, 1.0)</span>
<span class="sd">            &gt;&gt;&gt; td.get(&quot;a&quot;)</span>
<span class="sd">            tensor([[1., 1., 1., 1.],</span>
<span class="sd">                    [0., 0., 0., 0.],</span>
<span class="sd">                    [0., 0., 0., 0.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Out-of-place version of masked_fill</span>

<span class="sd">        Args:</span>
<span class="sd">            mask (boolean torch.Tensor): mask of values to be filled. Shape</span>
<span class="sd">                must match tensordict shape.</span>
<span class="sd">            value: value to used to fill the tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3, 4)},</span>
<span class="sd">            ...     batch_size=[3])</span>
<span class="sd">            &gt;&gt;&gt; mask = torch.tensor([True, False, False])</span>
<span class="sd">            &gt;&gt;&gt; td1 = td.masked_fill(mask, 1.0)</span>
<span class="sd">            &gt;&gt;&gt; td1.get(&quot;a&quot;)</span>
<span class="sd">            tensor([[1., 1., 1., 1.],</span>
<span class="sd">                    [0., 0., 0., 0.],</span>
<span class="sd">                    [0., 0., 0., 0.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">masked_select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Masks all tensors of the TensorDict and return a new TensorDict</span>
<span class="sd">        instance with similar keys pointing to masked values.</span>

<span class="sd">        Args:</span>
<span class="sd">            mask (torch.Tensor): boolean mask to be used for the tensors.</span>
<span class="sd">                Shape must match the TensorDict batch_size.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3, 4)},</span>
<span class="sd">            ...    batch_size=[3])</span>
<span class="sd">            &gt;&gt;&gt; mask = torch.tensor([True, False, False])</span>
<span class="sd">            &gt;&gt;&gt; td_mask = td.masked_select(mask)</span>
<span class="sd">            &gt;&gt;&gt; td_mask.get(&quot;a&quot;)</span>
<span class="sd">            tensor([[0., 0., 0., 0.]])</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">while</span> <span class="n">mask</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
                <span class="n">mask_expand</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mask_expand</span> <span class="o">=</span> <span class="n">mask</span>
            <span class="n">value_select</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">mask_expand</span><span class="p">]</span>
            <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_select</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">dim</span><span class="p">]))</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>
<span class="sd">            boolean indicating if all the tensors are contiguous.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict of the same type with contiguous values (</span>
<span class="sd">            or self if values are already contiguous).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>
<span class="sd">            dictionary with key-value pairs matching those of the</span>
<span class="sd">            tensordict.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="k">else</span> <span class="n">value</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Unsqueeze all tensors for a dimension comprised in between</span>
<span class="sd">        `-td.batch_dims` and `td.batch_dims` and returns them in a new</span>
<span class="sd">        tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension along which to unsqueeze</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;unsqueezing is allowed for dims comprised between &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`-td.batch_dims` and `td.batch_dims` only. Got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> with a batch size of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">UnsqueezedTensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">custom_op</span><span class="o">=</span><span class="s2">&quot;unsqueeze&quot;</span><span class="p">,</span>
            <span class="n">inv_op</span><span class="o">=</span><span class="s2">&quot;squeeze&quot;</span><span class="p">,</span>
            <span class="n">custom_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="n">dim</span><span class="p">},</span>
            <span class="n">inv_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="n">dim</span><span class="p">},</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Squeezes all tensors for a dimension comprised in between</span>
<span class="sd">        `-td.batch_dims+1` and `td.batch_dims-1` and returns them</span>
<span class="sd">        in a new tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension along which to squeeze</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;squeezing is allowed for dims comprised between 0 and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;td.batch_dims only. Got dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> and batch_size&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">SqueezedTensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">custom_op</span><span class="o">=</span><span class="s2">&quot;squeeze&quot;</span><span class="p">,</span>
            <span class="n">inv_op</span><span class="o">=</span><span class="s2">&quot;unsqueeze&quot;</span><span class="p">,</span>
            <span class="n">custom_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="n">dim</span><span class="p">},</span>
            <span class="n">inv_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dim&quot;</span><span class="p">:</span> <span class="n">dim</span><span class="p">},</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">shape</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a contiguous, reshaped tensor of the desired shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            *shape (int): new shape of the resulting tensordict.</span>
<span class="sd">            size: iterable</span>

<span class="sd">        Returns:</span>
<span class="sd">            A TensorDict with reshaped keys</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">item</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="p">:])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Implicit reshaping is not permitted with empty &quot;</span> <span class="s2">&quot;tensordicts&quot;</span>
                <span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">view</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">shape</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a tensordict with views of the tensors according to a new</span>
<span class="sd">        shape, compatible with the tensordict batch_size.</span>

<span class="sd">        Args:</span>
<span class="sd">            *shape (int): new shape of the resulting tensordict.</span>
<span class="sd">            size: iterable</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict with the desired batch_size.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3,4,5),</span>
<span class="sd">            ...    &#39;b&#39;: torch.zeros(3,4,10,1)}, batch_size=torch.Size([3, 4]))</span>
<span class="sd">            &gt;&gt;&gt; td_view = td.view(12)</span>
<span class="sd">            &gt;&gt;&gt; print(td_view.get(&quot;a&quot;).shape)  # torch.Size([12, 5])</span>
<span class="sd">            &gt;&gt;&gt; print(td_view.get(&quot;b&quot;).shape)  # torch.Size([12, 10, 1])</span>
<span class="sd">            &gt;&gt;&gt; td_view = td.view(-1, 4, 3)</span>
<span class="sd">            &gt;&gt;&gt; print(td_view.get(&quot;a&quot;).shape)  # torch.Size([1, 4, 3, 5])</span>
<span class="sd">            &gt;&gt;&gt; print(td_view.get(&quot;b&quot;).shape)  # torch.Size([1, 4, 3, 10, 1])</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">infer_size_impl</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">ViewedTensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">custom_op</span><span class="o">=</span><span class="s2">&quot;view&quot;</span><span class="p">,</span>
            <span class="n">inv_op</span><span class="o">=</span><span class="s2">&quot;view&quot;</span><span class="p">,</span>
            <span class="n">custom_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="n">shape</span><span class="p">},</span>
            <span class="n">inv_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">},</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">permute</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">dims_list</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a view of a tensordict with the batch dimensions permuted according to dims</span>

<span class="sd">        Args:</span>
<span class="sd">            *dims_list (int): the new ordering of the batch dims of the tensordict. Alternatively,</span>
<span class="sd">                a single iterable of integers can be provided.</span>
<span class="sd">            dims (list of int): alternative way of calling permute(...).</span>

<span class="sd">        Returns:</span>
<span class="sd">            a new tensordict with the batch dimensions in the desired order.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; tensordict = TensorDict({&quot;a&quot;: torch.randn(3, 4, 5)}, [3, 4])</span>
<span class="sd">            &gt;&gt;&gt; print(tensordict.permute([1, 0]))</span>
<span class="sd">            PermutedTensorDict(</span>
<span class="sd">                source=TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32)},</span>
<span class="sd">                    batch_size=torch.Size([3, 4]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                op=permute(dims=[1, 0]))</span>
<span class="sd">            &gt;&gt;&gt; print(tensordict.permute(1, 0))</span>
<span class="sd">            PermutedTensorDict(</span>
<span class="sd">                source=TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32)},</span>
<span class="sd">                    batch_size=torch.Size([3, 4]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                op=permute(dims=[1, 0]))</span>
<span class="sd">            &gt;&gt;&gt; print(tensordict.permute(dims=[1, 0]))</span>
<span class="sd">            PermutedTensorDict(</span>
<span class="sd">                source=TensorDict(</span>
<span class="sd">                    fields={</span>
<span class="sd">                        a: Tensor(torch.Size([3, 4, 5]), dtype=torch.float32)},</span>
<span class="sd">                    batch_size=torch.Size([3, 4]),</span>
<span class="sd">                    device=cpu,</span>
<span class="sd">                    is_shared=False),</span>
<span class="sd">                op=permute(dims=[1, 0]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dims_list</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">dims_list</span> <span class="o">=</span> <span class="n">dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;number of dims don&#39;t match in permute (got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">dims_list</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">min_dim</span><span class="p">,</span> <span class="n">max_dim</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">seen</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">dims_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">min_dim</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&gt;</span> <span class="n">max_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;dimension out of range (expected to be in range of [</span><span class="si">{</span><span class="n">min_dim</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">max_dim</span><span class="si">}</span><span class="s2">], but got </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">seen</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;repeated dim in permute&quot;</span><span class="p">)</span>
            <span class="n">seen</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="n">PermutedTensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">custom_op</span><span class="o">=</span><span class="s2">&quot;permute&quot;</span><span class="p">,</span>
            <span class="n">inv_op</span><span class="o">=</span><span class="s2">&quot;permute&quot;</span><span class="p">,</span>
            <span class="n">custom_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dims&quot;</span><span class="p">:</span> <span class="n">dims_list</span><span class="p">},</span>
            <span class="n">inv_op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dims&quot;</span><span class="p">:</span> <span class="n">dims_list</span><span class="p">},</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">_td_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">field_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fields=</span><span class="se">{{</span><span class="si">{</span><span class="n">fields</span><span class="si">}</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">batch_size_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;batch_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">device_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;device=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">is_shared_str</span> <span class="o">=</span> <span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;is_shared=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">string</span> <span class="o">=</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">field_str</span><span class="p">,</span> <span class="n">batch_size_str</span><span class="p">,</span> <span class="n">device_str</span><span class="p">,</span> <span class="n">is_shared_str</span><span class="p">])</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="n">string</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="k">def</span> <span class="nf">all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Checks if all values are True/non-null in the tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int, optional): if None, returns a boolean indicating</span>
<span class="sd">                whether all tensors return `tensor.all() == True`</span>
<span class="sd">                If integer, all is called upon the dimension specified if</span>
<span class="sd">                and only if this dimension is compatible with the tensordict</span>
<span class="sd">                shape.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;dim must be greater than -tensordict.batch_dims and smaller &quot;</span>
                <span class="s2">&quot;than tensordict.batchdims&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span>
            <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="n">source</span><span class="o">=</span><span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="n">b</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">any</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Checks if any value is True/non-null in the tensordict.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int, optional): if None, returns a boolean indicating</span>
<span class="sd">                whether all tensors return `tensor.any() == True`.</span>
<span class="sd">                If integer, all is called upon the dimension specified if</span>
<span class="sd">                and only if this dimension is compatible with</span>
<span class="sd">                the tensordict shape.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;dim must be greater than -tensordict.batch_dims and smaller &quot;</span>
                <span class="s2">&quot;than tensordict.batchdims&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span>
            <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="n">source</span><span class="o">=</span><span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="n">b</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">([</span><span class="n">value</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">get_sub_tensordict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a SubTensorDict with the desired index.&quot;&quot;&quot;</span>
        <span class="n">sub_td</span> <span class="o">=</span> <span class="n">SubTensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">sub_td</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>
        <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">flatten_keys</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">separator</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">to_flatten</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">meta_value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">meta_value</span><span class="o">.</span><span class="n">is_tensordict</span><span class="p">():</span>
                <span class="n">to_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">to_flatten</span><span class="p">:</span>
                <span class="n">inner_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span>
                    <span class="n">separator</span><span class="o">=</span><span class="n">separator</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">inner_key</span><span class="p">,</span> <span class="n">inner_item</span> <span class="ow">in</span> <span class="n">inner_tensordict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">separator</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">key</span><span class="p">,</span> <span class="n">inner_key</span><span class="p">]),</span> <span class="n">inner_item</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">to_flatten</span><span class="p">:</span>
                <span class="k">del</span> <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensordict_out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="p">{},</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">to_flatten</span><span class="p">:</span>
                    <span class="n">inner_tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">flatten_keys</span><span class="p">(</span>
                        <span class="n">separator</span><span class="o">=</span><span class="n">separator</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">inner_key</span><span class="p">,</span> <span class="n">inner_item</span> <span class="ow">in</span> <span class="n">inner_tensordict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">tensordict_out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">separator</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">key</span><span class="p">,</span> <span class="n">inner_key</span><span class="p">]),</span> <span class="n">inner_item</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tensordict_out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensordict_out</span>

    <span class="k">def</span> <span class="nf">unflatten_keys</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">separator</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">to_unflatten</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="nb">list</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">separator</span> <span class="ow">in</span> <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">split_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">separator</span><span class="p">)</span>
                <span class="n">to_unflatten</span><span class="p">[</span><span class="n">split_key</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">separator</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">split_key</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">value</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">separator</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">},</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">list_of_keys</span> <span class="ow">in</span> <span class="n">to_unflatten</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">new_key</span><span class="p">)</span> <span class="ow">in</span> <span class="n">list_of_keys</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span>
                <span class="n">tensordict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">unflatten_keys</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="n">separator</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>
<span class="sd">            Length of first dimension, if there is, otherwise 0.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Indexes all tensors according to idx and returns a new tensordict</span>
<span class="sd">        where the values share the storage of the original tensors (even</span>
<span class="sd">        when the index is a torch.Tensor). Any in-place modification to the</span>
<span class="sd">        resulting tensordict will impact the parent tensordict too.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; td = TensorDict(source={&#39;a&#39;: torch.zeros(3,4,5)},</span>
<span class="sd">            ...     batch_size=torch.Size([3, 4]))</span>
<span class="sd">            &gt;&gt;&gt; subtd = td[torch.zeros(1, dtype=torch.long)]</span>
<span class="sd">            &gt;&gt;&gt; assert subtd.shape == torch.Size([1,4])</span>
<span class="sd">            &gt;&gt;&gt; subtd.set(&quot;a&quot;, torch.ones(1,4,5))</span>
<span class="sd">            &gt;&gt;&gt; print(td.get(&quot;a&quot;))  # first row is full of 1</span>
<span class="sd">            &gt;&gt;&gt; # Warning: this will not work as expected</span>
<span class="sd">            &gt;&gt;&gt; subtd.get(&quot;a&quot;)[:] = 2.0</span>
<span class="sd">            &gt;&gt;&gt; print(td.get(&quot;a&quot;))  # values have not changed</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">sub_index</span>
                <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">idx</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">_idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="n">_STR_MIXED_INDEX_ERROR</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_idx</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;indexing a tensordict with td.batch_dims==0 is not permitted&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="ow">is</span> <span class="bp">Ellipsis</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">Ellipsis</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">convert_ellipsis_to_idx</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># if return_simple_view and not self.is_memmap():</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="n">_meta_source</span><span class="o">=</span><span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">(</span><span class="n">make_unset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">item</span><span class="o">.</span><span class="n">is_tensordict</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">_getitem_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">idx</span><span class="p">),</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="bp">Ellipsis</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">Ellipsis</span> <span class="ow">in</span> <span class="n">index</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">convert_ellipsis_to_idx</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">index</span>
        <span class="p">):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">sub_index</span>
                <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">index</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">_index</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">_index</span> <span class="ow">in</span> <span class="n">index</span>
        <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="n">_STR_MIXED_INDEX_ERROR</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_inplace_set</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">index</span>
        <span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                        <span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">SubTensorDict</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">index</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">SubTensorDict</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;for populating tensordict with new key-value pair&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Trying to replace an existing nested tensordict with &quot;</span>
                        <span class="s2">&quot;another one with non-matching keys. This leads to &quot;</span>
                        <span class="s2">&quot;unspecified behaviours and is prohibited.&quot;</span>
                    <span class="p">)</span>
                <span class="k">raise</span> <span class="n">err</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indexed_bs</span> <span class="o">=</span> <span class="n">_getitem_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">indexed_bs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">indexed_bs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;indexed destination TensorDict batch size is </span><span class="si">{</span><span class="n">indexed_bs</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;(batch_size = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, index=</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">), &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;which differs from the source batch size </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="n">subtd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sub_tensordict</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">subtd</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index has to a string but received </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Renames a key with a new string.</span>

<span class="sd">        Args:</span>
<span class="sd">            old_key (str): key to be renamed</span>
<span class="sd">            new_key (str): new name</span>
<span class="sd">            safe (bool, optional): if True, an error is thrown when the new</span>
<span class="sd">                key is already present in the TensorDict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Fills a tensor pointed by the key with the a given value.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (str): key to be remaned</span>
<span class="sd">            value (Number, bool): value to use for the filling</span>

<span class="sd">        Returns:</span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">meta_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">device</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">if</span> <span class="n">meta_tensor</span><span class="o">.</span><span class="n">is_tensordict</span><span class="p">():</span>
            <span class="n">tensordict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">tensordict</span><span class="o">.</span><span class="n">apply_</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a new, empty tensordict with the same device and batch size.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">is_empty</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_locked</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_is_locked&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_locked</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_locked</span>

    <span class="nd">@is_locked</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">is_locked</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_locked</span> <span class="o">=</span> <span class="n">value</span>


<div class="viewcode-block" id="TensorDict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict">[docs]</a><span class="k">class</span> <span class="nc">TensorDict</span><span class="p">(</span><span class="n">TensorDictBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A batched dictionary of tensors.</span>

<span class="sd">    TensorDict is a tensor container where all tensors are stored in a</span>
<span class="sd">    key-value pair fashion and where each element shares at least the</span>
<span class="sd">    following features:</span>
<span class="sd">    - memory location (shared, memory-mapped array, ...);</span>
<span class="sd">    - batch size (i.e. n^th first dimensions).</span>

<span class="sd">    Additionally, if the tensordict has a specified device, then each element</span>
<span class="sd">    must share that device.</span>

<span class="sd">    TensorDict instances support many regular tensor operations as long as</span>
<span class="sd">    they are dtype-independent (as a TensorDict instance can contain tensors</span>
<span class="sd">    of many different dtypes). Those operations include (but are not limited</span>
<span class="sd">    to):</span>

<span class="sd">    - operations on shape: when a shape operation is called (indexing,</span>
<span class="sd">      reshape, view, expand, transpose, permute,</span>
<span class="sd">      unsqueeze, squeeze, masking etc), the operations is done as if it</span>
<span class="sd">      was done on a tensor of the same shape as the batch size then</span>
<span class="sd">      expended to the right, e.g.:</span>

<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;a&#39;: torch.zeros(3,4,5)}, batch_size=[3, 4])</span>
<span class="sd">        &gt;&gt;&gt; # returns a TensorDict of batch size [3, 4, 1]</span>
<span class="sd">        &gt;&gt;&gt; td_unsqueeze = td.unsqueeze(-1)</span>
<span class="sd">        &gt;&gt;&gt; # returns a TensorDict of batch size [12]</span>
<span class="sd">        &gt;&gt;&gt; td_view = td.view(-1)</span>
<span class="sd">        &gt;&gt;&gt; # returns a tensor of batch size [12, 4]</span>
<span class="sd">        &gt;&gt;&gt; a_view = td.view(-1).get(&quot;a&quot;)</span>

<span class="sd">    - casting operations: a TensorDict can be cast on a different device</span>
<span class="sd">      or another TensorDict type using</span>

<span class="sd">        &gt;&gt;&gt; td_cpu = td.to(&quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; td_savec = td.to(SavedTensorDict)  # TensorDict saved on disk</span>
<span class="sd">        &gt;&gt;&gt; dictionary = td.to_dict()</span>

<span class="sd">      A call of the `.to()` method with a dtype will return an error.</span>

<span class="sd">    - Cloning, contiguous</span>

<span class="sd">    - Reading: `td.get(key)`, `td.get_at(key, index)`</span>

<span class="sd">    - Content modification: `td.set(key, value)`, `td.set_(key, value)`,</span>
<span class="sd">      `td.update(td_or_dict)`, `td.update_(td_or_dict)`, `td.fill_(key,</span>
<span class="sd">      value)`, `td.rename_key(old_name, new_name)`, etc.</span>

<span class="sd">    - Operations on multiple tensordicts: `torch.cat(tensordict_list, dim)`,</span>
<span class="sd">      `torch.stack(tensordict_list, dim)`, `td1 == td2` etc.</span>

<span class="sd">    Args:</span>
<span class="sd">        source (TensorDict or dictionary): a data source. If empty, the</span>
<span class="sd">            tensordict can be populated subsequently.</span>
<span class="sd">        batch_size (iterable of int, optional): a batch size for the</span>
<span class="sd">            tensordict. The batch size is immutable and can only be modified</span>
<span class="sd">            by calling operations that create a new TensorDict. Unless the</span>
<span class="sd">            source is another TensorDict, the batch_size argument must be</span>
<span class="sd">            provided as it won&#39;t be inferred from the data.</span>
<span class="sd">        device (torch.device or compatible type, optional): a device for the</span>
<span class="sd">            TensorDict.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; source = {&#39;random&#39;: torch.randn(3, 4),</span>
<span class="sd">        ...     &#39;zeros&#39;: torch.zeros(3, 4, 5)}</span>
<span class="sd">        &gt;&gt;&gt; batch_size = [3]</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(source, batch_size)</span>
<span class="sd">        &gt;&gt;&gt; print(td.shape)  # equivalent to td.batch_size</span>
<span class="sd">        torch.Size([3])</span>
<span class="sd">        &gt;&gt;&gt; td_unqueeze = td.unsqueeze(-1)</span>
<span class="sd">        &gt;&gt;&gt; print(td_unqueeze.get(&quot;zeros&quot;).shape)</span>
<span class="sd">        torch.Size([3, 1, 4, 5])</span>
<span class="sd">        &gt;&gt;&gt; print(td_unqueeze[0].shape)</span>
<span class="sd">        torch.Size([1])</span>
<span class="sd">        &gt;&gt;&gt; print(td_unqueeze.view(-1).shape)</span>
<span class="sd">        torch.Size([3])</span>
<span class="sd">        &gt;&gt;&gt; print((td.clone()==td).all())</span>
<span class="sd">        True</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_safe</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">TensorDictBase</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_meta_source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_run_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">_is_shared</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_is_memmap</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="n">_is_shared</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="n">_is_memmap</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;A TensorDict source is expected to be a TensorDictBase &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;sub-type or a dictionary, found type(source)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">source</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="n">Number</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">batch_size</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;batch size was not specified when creating the TensorDict &quot;</span>
                <span class="s2">&quot;instance and it could not be retrieved from source.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="k">if</span> <span class="n">source</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">source</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                        <span class="n">value</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span>
                        <span class="n">_run_checks</span><span class="o">=</span><span class="n">_run_checks</span><span class="p">,</span>
                        <span class="n">_is_shared</span><span class="o">=</span><span class="n">_is_shared</span><span class="p">,</span>
                        <span class="n">_is_memmap</span><span class="o">=</span><span class="n">_is_memmap</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">_meta_val</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">_meta_source</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_meta_source</span>
                    <span class="k">else</span> <span class="n">_meta_source</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>
                    <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="p">):</span>
                    <span class="n">value</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">_meta_val</span><span class="o">=</span><span class="n">_meta_val</span><span class="p">,</span> <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_run_checks</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_batch_size</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_device</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="n">proc_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">is_memmap</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">proc_value</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">is_shared</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">proc_value</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">proc_value</span><span class="p">,</span> <span class="p">(</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">))</span>
            <span class="ow">or</span> <span class="ow">not</span> <span class="n">is_batchedtensor</span><span class="p">(</span><span class="n">proc_value</span><span class="p">)</span>
            <span class="k">else</span> <span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">MetaTensor</span><span class="p">(</span>
            <span class="n">proc_value</span><span class="p">,</span>
            <span class="n">_is_memmap</span><span class="o">=</span><span class="n">is_memmap</span><span class="p">,</span>
            <span class="n">_is_shared</span><span class="o">=</span><span class="n">is_shared</span><span class="p">,</span>
            <span class="n">_is_tensordict</span><span class="o">=</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">proc_value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="nd">@batch_dims</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Setting batch dims on </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> instances is &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;not allowed.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns `None` if device hasn&#39;t been provided in the constructor</span>
<span class="sd">        or set via `tensordict.to(device)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;device cannot be set using tensordict.device = device, &quot;</span>
            <span class="s2">&quot;because device cannot be updated in-place. To update device, use &quot;</span>
            <span class="s2">&quot;tensordict.to(new_device), which will return a new tensordict &quot;</span>
            <span class="s2">&quot;on the new device.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_orig_batch_size&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">new_size</span>

    <span class="c1"># Checks</span>
    <span class="k">def</span> <span class="nf">_check_is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">share_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">share_list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">share_list</span><span class="p">):</span>
            <span class="n">shared_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()]</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;tensors must be either all shared or not, but mixed &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;features is not allowed. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Found: </span><span class="si">{</span><span class="n">shared_str</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">share_list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">share_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_check_is_memmap</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">memmap_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">memmap_list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">memmap_list</span><span class="p">):</span>
            <span class="n">memmap_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()]</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;tensors must be either all MemmapTensor or not, but mixed &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;features is not allowed. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Found: </span><span class="si">{</span><span class="n">memmap_str</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">memmap_list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">memmap_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_check_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">devices</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">devices</span> <span class="o">!=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;TensorDict.device is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="si">}</span><span class="s2">, but elements have &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;device values </span><span class="si">{</span><span class="n">devices</span><span class="si">}</span><span class="s2">. If TensorDict.device is set then &quot;</span>
                <span class="s2">&quot;all elements must share that device.&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="TensorDict.pin_memory"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.pin_memory">[docs]</a>    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                    <span class="n">value</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.expand"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.expand">[docs]</a>    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Expands every tensor with `(*shape, *tensor.shape)` and returns the</span>
<span class="sd">        same tensordict with new tensors with expanded shapes.</span>
<span class="sd">        Supports iterables to specify the shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">tensordict_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># new shape dim check</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;the number of sizes provided (</span><span class="si">{shape_dim}</span><span class="s2">) must be greater or equal to the number of &quot;</span>
                <span class="s2">&quot;dimensions in the TensorDict (</span><span class="si">{tensordict_dim}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">shape_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">tensordict_dim</span><span class="o">=</span><span class="n">tensordict_dims</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># new shape compatability check</span>
        <span class="k">for</span> <span class="n">old_dim</span><span class="p">,</span> <span class="n">new_dim</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="n">tensordict_dims</span><span class="p">:]):</span>
            <span class="k">if</span> <span class="n">old_dim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">new_dim</span> <span class="o">!=</span> <span class="n">old_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Incompatible expanded shape: The expanded shape length at non-singleton dimension should be same &quot;</span>
                    <span class="s2">&quot;as the original length. target_shape = </span><span class="si">{new_shape}</span><span class="s2">, existing_shape = </span><span class="si">{old_shape}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">new_shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">old_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensor_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">last_n_dims</span> <span class="o">=</span> <span class="n">tensor_dims</span> <span class="o">-</span> <span class="n">tensordict_dims</span>
                <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="n">last_n_dims</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="n">shape</span><span class="p">],</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="TensorDict.set"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.set">[docs]</a>    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">_run_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">_meta_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MetaTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Sets a value in the TensorDict. If inplace=True (default is False),</span>
<span class="sd">        and if the key already exists, set will call set_ (in place setting).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">inplace</span> <span class="ow">or</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify locked TensorDict&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected key to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">NotImplementedError</span><span class="p">:</span>
                <span class="c1"># when running functorch, a NotImplementedError may be raised</span>
                <span class="k">pass</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="c1"># when setting a value of type dict</span>
                <span class="k">pass</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">)</span>

        <span class="n">present</span> <span class="o">=</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span>
        <span class="k">if</span> <span class="n">present</span> <span class="ow">and</span> <span class="n">value</span> <span class="ow">is</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">present</span> <span class="ow">and</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="n">proc_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">check_tensor_shape</span><span class="o">=</span><span class="n">_run_checks</span><span class="p">,</span>
            <span class="n">check_shared</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">check_device</span><span class="o">=</span><span class="n">_run_checks</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># check_tensor_shape=_run_checks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">proc_value</span>
        <span class="k">if</span> <span class="n">_meta_val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_meta_val</span>
        <span class="k">elif</span> <span class="n">present</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.del_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.del_">[docs]</a>    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.rename_key"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.rename_key">[docs]</a>    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected old_name to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected new_name to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">new_key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">safe</span> <span class="ow">and</span> <span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s2"> already present in TensorDict.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="n">new_key</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">old_key</span><span class="p">),</span>
            <span class="n">_meta_val</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span> <span class="k">if</span> <span class="n">old_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.set_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.set_">[docs]</a>    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected key to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">no_check</span> <span class="ow">or</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">no_check</span><span class="p">:</span>
                <span class="n">proc_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                    <span class="n">value</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_shared</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                <span class="c1"># copy_ will broadcast one tensor onto another&#39;s shape, which we don&#39;t want</span>
                <span class="n">target_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
                <span class="k">if</span> <span class="n">proc_value</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">target_shape</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;calling set_(&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;, tensor) with tensors of &#39;</span>
                        <span class="sa">f</span><span class="s2">&quot;different shape: got tensor.shape=</span><span class="si">{</span><span class="n">proc_value</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;and get(&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;).shape=</span><span class="si">{</span><span class="n">target_shape</span><span class="si">}</span><span class="s1">&#39;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">proc_value</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">proc_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">proc_value</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">proc_value</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;key &quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot; not found in tensordict, &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;call td.set(&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;, value) for populating tensordict with &#39;</span>
                <span class="sa">f</span><span class="s2">&quot;new key-value pair&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">list_item</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_stack_onto_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">_idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">))</span> <span class="k">for</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">list_item</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot stack onto an indexed tensor with index </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;as its storage differs.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="TensorDict.set_at_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.set_at_">[docs]</a>    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected key to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># do we need this?</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;did not find key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">tensor_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Multiple indexing can lead to unexpected behaviours when &quot;</span>
                <span class="s2">&quot;setting items, for instance `td[idx1][idx2] = other` may &quot;</span>
                <span class="s2">&quot;not write to the desired location if idx1 is a list/tensor.&quot;</span>
            <span class="p">)</span>
            <span class="n">tensor_in</span> <span class="o">=</span> <span class="n">_sub_index</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
            <span class="n">tensor_in</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor_in</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="c1"># change Meta in case of require_grad coming in value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">tensor_in</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.get"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.get">[docs]</a>    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected key to be a string but found </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorDict.share_memory_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.share_memory_">[docs]</a>    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;memmap and shared memory are mutually exclusive features.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;share_memory_ must be called when the TensorDict is (&quot;</span>
                <span class="s2">&quot;partially) populated. Set a tensor first.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="c1"># cuda tensors are shared by default</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="c1"># no need to consider MemmapTensors here as we have checked that this is not a memmap-tensordict</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>
                <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">value</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">():</span>
            <span class="n">value</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.detach_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.detach_">[docs]</a>    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">value</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.memmap_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.memmap_">[docs]</a>    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;memmap and shared memory are mutually exclusive features.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;memmap_() must be called when the TensorDict is (partially) &quot;</span>
                <span class="s2">&quot;populated. Set a tensor first.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;memmap is not compatible with gradients, one of Tensors has requires_grad equals True&quot;</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">MemmapTensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values_meta</span><span class="p">():</span>
            <span class="n">value</span><span class="o">.</span><span class="n">memmap_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">Type</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">dest</span><span class="p">(</span>
                <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">td</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="c1"># must be device</span>
            <span class="n">dest</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dest</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>

            <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">dest</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_tensordict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">self_copy</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_dict_meta</span> <span class="o">=</span> <span class="n">KeyDependentDefaultDict</span><span class="p">(</span><span class="n">self_copy</span><span class="o">.</span><span class="n">_make_meta</span><span class="p">)</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="n">self_copy</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">dest</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dest must be a string, torch.device or a TensorDict &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;instance, </span><span class="si">{</span><span class="n">dest</span><span class="si">}</span><span class="s2"> not allowed&quot;</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="TensorDict.masked_fill_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.masked_fill_">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">mask_expand</span> <span class="o">=</span> <span class="n">expand_as_right</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="n">item</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask_expand</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.masked_fill"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.masked_fill">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_copy</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorDict.is_contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.is_contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">value</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span></div>

<div class="viewcode-block" id="TensorDict.contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TensorDict.select"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.select">[docs]</a>    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">}</span>
        <span class="n">d_meta</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items_meta</span><span class="p">(</span><span class="n">make_unset</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span> <span class="o">=</span> <span class="n">d</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
            <span class="n">_meta_source</span><span class="o">=</span><span class="n">d_meta</span><span class="p">,</span>
            <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_is_memmap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span><span class="p">,</span>
            <span class="n">_is_shared</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="TensorDict.keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.TensorDict.html#torchrl.data.TensorDict.keys">[docs]</a>    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KeysView</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span></div></div>


<span class="k">class</span> <span class="nc">_ErrorInteceptor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Context manager for catching errors and modifying message. Intended for</span>
<span class="sd">    use with stacking / concatenation operations applied to TensorDicts.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_EXC_MSG</span> <span class="o">=</span> <span class="s2">&quot;Expected all tensors to be on the same device&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">exc_msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exc_type</span> <span class="o">=</span> <span class="n">exc_type</span> <span class="k">if</span> <span class="n">exc_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="ne">RuntimeError</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exc_msg</span> <span class="o">=</span> <span class="n">exc_msg</span> <span class="k">if</span> <span class="n">exc_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_EXC_MSG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prefix</span> <span class="o">=</span> <span class="n">prefix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">key</span>

    <span class="k">def</span> <span class="nf">_add_key_to_error_msg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix</span><span class="p">):</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix</span><span class="si">}</span><span class="s1"> &quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot; /</span><span class="si">{</span><span class="n">msg</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix</span><span class="p">):]</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix</span><span class="si">}</span><span class="s1"> &quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;. </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s1">&#39;</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_value</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">exc_type</span> <span class="ow">is</span> <span class="bp">self</span><span class="o">.</span><span class="n">exc_type</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exc_msg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">exc_msg</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">exc_value</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">exc_value</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_key_to_error_msg</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">exc_value</span><span class="p">)),)</span>


<span class="k">def</span> <span class="nf">implements_for_td</span><span class="p">(</span><span class="n">torch_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Register a torch function override for ScalarTensor&quot;&quot;&quot;</span>

    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">torch_function</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="n">TD_HANDLED_FUNCTIONS</span><span class="p">[</span><span class="n">torch_function</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">return</span> <span class="n">decorator</span>


<span class="c1"># @implements_for_td(torch.testing.assert_allclose) TODO</span>
<span class="k">def</span> <span class="nf">assert_allclose_td</span><span class="p">(</span>
    <span class="n">actual</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">expected</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
    <span class="n">rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">equal_nan</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">msg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">expected</span><span class="p">,</span> <span class="n">TensorDictBase</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;assert_allclose inputs must be of TensorDict type&quot;</span><span class="p">)</span>
    <span class="n">set1</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">actual</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">set2</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">set1</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">set2</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">set1</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
            <span class="s2">&quot;actual and expected tensordict keys mismatch, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;keys </span><span class="si">{</span><span class="p">(</span><span class="n">set1</span> <span class="o">-</span> <span class="n">set2</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">set2</span> <span class="o">-</span> <span class="n">set1</span><span class="p">)</span><span class="si">}</span><span class="s2"> appear in one but not &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;the other.&quot;</span>
        <span class="p">)</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">actual</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
        <span class="n">input1</span> <span class="o">=</span> <span class="n">actual</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">input2</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="n">assert_allclose_td</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">mse</span> <span class="o">=</span> <span class="p">(</span><span class="n">input1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="o">-</span> <span class="n">input2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="n">mse</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">input1</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">default_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> does not match, got mse = </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">4.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">msg</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">default_msg</span><span class="p">,</span> <span class="n">msg</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="n">default_msg</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">):</span>
            <span class="n">input1</span> <span class="o">=</span> <span class="n">input1</span><span class="o">.</span><span class="n">_tensor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input2</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">):</span>
            <span class="n">input2</span> <span class="o">=</span> <span class="n">input2</span><span class="o">.</span><span class="n">_tensor</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span>
            <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="n">equal_nan</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">msg</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unbind</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">full_like</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">td_clone</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;dtype&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot pass dtype to full_like with TensorDict&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;device&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;keyword arguments </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> are not &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;supported with full_like with TensorDict&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">td_clone</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">td_clone</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;dtype&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot pass dtype to full_like with TensorDict&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;device&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;keyword arguments </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> are not &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;supported with full_like with TensorDict&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">td_clone</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ones_like</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">td_clone</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;device&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">td_clone</span> <span class="o">=</span> <span class="n">td_clone</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;keyword arguments </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> are not &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;supported with full_like with TensorDict&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">td_clone</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">masked_select</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">permute</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">permute</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cat</span><span class="p">(</span>
    <span class="n">list_of_tensordicts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">list_of_tensordicts</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;list_of_tensordicts cannot be empty&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;negative dim in torch.dim(list_of_tensordicts, dim=dim) not &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;allowed, got dim=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;dim must be in the range 0 &lt;= dim &lt; len(batch_size), got dim&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> and batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">td</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="c1"># check that all tensordict match</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">_check_keys</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">_ErrorInteceptor</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span> <span class="s2">&quot;Attempted to concatenate tensors on different devices at key&quot;</span>
            <span class="p">):</span>
                <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span> <span class="n">dim</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;out.batch_size and cat batch size must match, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got out.batch_size=</span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> and batch_size&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">_ErrorInteceptor</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span> <span class="s2">&quot;Attempted to concatenate tensors on different devices at key&quot;</span>
            <span class="p">):</span>
                <span class="n">out</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span> <span class="n">dim</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="nd">@implements_for_td</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">stack</span><span class="p">(</span>
    <span class="n">list_of_tensordicts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">contiguous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">list_of_tensordicts</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;list_of_tensordicts cannot be empty&quot;</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">if</span> <span class="n">td</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;stacking tensordicts requires them to have congruent &quot;</span>
                    <span class="s2">&quot;batch sizes, got td1.batch_size=</span><span class="si">{td.batch_size}</span><span class="s2"> and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;td2.batch_size</span><span class="si">{</span><span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
    <span class="c1"># check that all tensordict match</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">_check_keys</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">list_of_tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">contiguous</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">_ErrorInteceptor</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="s2">&quot;Attempted to stack tensors on different devices at key&quot;</span>
                <span class="p">):</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">_tensordict</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span>
                        <span class="n">dim</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="n">out</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">LazyStackedTensorDict</span><span class="o">.</span><span class="n">_compute_batch_size</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="n">list_of_tensordicts</span><span class="p">,</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch_size</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">))</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;out.batch_size and stacked batch size must match, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got out.batch_size=</span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> and batch_size&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">out_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">strict</span><span class="p">:</span>
            <span class="n">in_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_keys</span> <span class="o">-</span> <span class="n">in_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;The output tensordict has keys that are missing in the &quot;</span>
                    <span class="s2">&quot;tensordict that has to be written: {out_keys - in_keys}. &quot;</span>
                    <span class="s2">&quot;As per the call to `stack(..., strict=True)`, this &quot;</span>
                    <span class="s2">&quot;is not permitted.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_keys</span> <span class="o">-</span> <span class="n">out_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;The resulting tensordict has keys that are missing in &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;its destination: </span><span class="si">{</span><span class="n">in_keys</span> <span class="o">-</span> <span class="n">out_keys</span><span class="si">}</span><span class="s2">. As per the call &quot;</span>
                    <span class="s2">&quot;to `stack(..., strict=True)`, this is not permitted.&quot;</span>
                <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_keys</span><span class="p">:</span>
                <span class="n">out</span><span class="o">.</span><span class="n">_stack_onto_</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">_tensordict</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span>
                    <span class="n">dim</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">_ErrorInteceptor</span><span class="p">(</span>
                    <span class="n">key</span><span class="p">,</span> <span class="s2">&quot;Attempted to stack tensors on different devices at key&quot;</span>
                <span class="p">):</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">_tensordict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                                <span class="k">for</span> <span class="n">_tensordict</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span>
                            <span class="p">],</span>
                            <span class="n">dim</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pads all tensors in a tensordict along the batch dimensions with a constant value,</span>
<span class="sd">    returning a new tensordict</span>

<span class="sd">    Args:</span>
<span class="sd">         tensordict (TensorDict): The tensordict to pad</span>
<span class="sd">         pad_size (Sequence[int]): The padding size by which to pad some batch</span>
<span class="sd">            dimensions of the tensordict, starting from the first dimension and</span>
<span class="sd">            moving forward. [len(pad_size) / 2] dimensions of the batch size will</span>
<span class="sd">            be padded. For example to pad only the first dimension, pad has the form</span>
<span class="sd">            (padding_left, padding_right). To pad two dimensions,</span>
<span class="sd">            (padding_left, padding_right, padding_top, padding_bottom) and so on.</span>
<span class="sd">            pad_size must be even and less than or equal to twice the number of batch dimensions.</span>
<span class="sd">         value (float, optional): The fill value to pad by, default 0.0</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new TensorDict padded along the batch dimensions</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict, pad</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;a&#39;: torch.ones(3, 4, 1),</span>
<span class="sd">        ...     &#39;b&#39;: torch.ones(3, 4, 1, 1)}, batch_size=[3, 4])</span>
<span class="sd">        &gt;&gt;&gt; dim0_left, dim0_right, dim1_left, dim1_right = [0, 1, 0, 2]</span>
<span class="sd">        &gt;&gt;&gt; padded_td = pad(td, [dim0_left, dim0_right, dim1_left, dim1_right], value=0.0)</span>
<span class="sd">        &gt;&gt;&gt; print(padded_td.batch_size)</span>
<span class="sd">        torch.Size([4, 6])</span>
<span class="sd">        &gt;&gt;&gt; print(padded_td.get(&quot;a&quot;).shape)</span>
<span class="sd">        torch.Size([4, 6, 1])</span>
<span class="sd">        &gt;&gt;&gt; print(padded_td.get(&quot;b&quot;).shape)</span>
<span class="sd">        torch.Size([4, 6, 1, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_size</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;The length of pad_size must be &lt;= 2 * the number of batch dimensions&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_size</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;pad_size must have an even number of dimensions&quot;</span><span class="p">)</span>

    <span class="n">new_batch_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pad_size</span><span class="p">)):</span>
        <span class="n">new_batch_size</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">pad_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">reverse_pad</span> <span class="o">=</span> <span class="n">pad_size</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">reverse_pad</span><span class="p">),</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">reverse_pad</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">reverse_pad</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">reverse_pad</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">reverse_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="n">new_batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensordict</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">cur_pad</span> <span class="o">=</span> <span class="n">reverse_pad</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_size</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">cur_pad</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">pad_size</span><span class="p">))</span> <span class="o">+</span> <span class="n">reverse_pad</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="n">padded</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">cur_pad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">padded</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="c1"># @implements_for_td(torch.nn.utils.rnn.pad_sequence)</span>
<span class="k">def</span> <span class="nf">pad_sequence_td</span><span class="p">(</span>
    <span class="n">list_of_tensordicts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">],</span>
    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">padding_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">TensorDictBase</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">list_of_tensordicts</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;list_of_tensordicts cannot be empty&quot;</span><span class="p">)</span>
    <span class="c1"># check that all tensordict match</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">_check_keys</span><span class="p">(</span><span class="n">list_of_tensordicts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="p">[],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">],</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
                    <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<div class="viewcode-block" id="SubTensorDict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict">[docs]</a><span class="k">class</span> <span class="nc">SubTensorDict</span><span class="p">(</span><span class="n">TensorDictBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A TensorDict that only sees an index of the stored tensors.</span>

<span class="sd">    By default, indexing a tensordict with an iterable will result in a</span>
<span class="sd">    SubTensorDict. This is done such that a TensorDict indexed with</span>
<span class="sd">    non-contiguous index (e.g. a Tensor) will still point to the original</span>
<span class="sd">    memory location (unlike regular indexing of tensors).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict, SubTensorDict</span>
<span class="sd">        &gt;&gt;&gt; source = {&#39;random&#39;: torch.randn(3, 4, 5, 6),</span>
<span class="sd">        ...    &#39;zeros&#39;: torch.zeros(3, 4, 1, dtype=torch.bool)}</span>
<span class="sd">        &gt;&gt;&gt; batch_size = torch.Size([3, 4])</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict(source, batch_size)</span>
<span class="sd">        &gt;&gt;&gt; td_index = td[:, 2]</span>
<span class="sd">        &gt;&gt;&gt; print(type(td_index), td_index.shape)</span>
<span class="sd">        &lt;class &#39;torchrl.data.tensordict.tensordict.TensorDict&#39;&gt; \</span>
<span class="sd">torch.Size([3])</span>
<span class="sd">        &gt;&gt;&gt; td_index = td[:, slice(None)]</span>
<span class="sd">        &gt;&gt;&gt; print(type(td_index), td_index.shape)</span>
<span class="sd">        &lt;class &#39;torchrl.data.tensordict.tensordict.TensorDict&#39;&gt; \</span>
<span class="sd">torch.Size([3, 4])</span>
<span class="sd">        &gt;&gt;&gt; td_index = td[:, Tensor([0, 2]).to(torch.long)]</span>
<span class="sd">        &gt;&gt;&gt; print(type(td_index), td_index.shape)</span>
<span class="sd">        &lt;class &#39;torchrl.data.tensordict.tensordict.SubTensorDict&#39;&gt; \</span>
<span class="sd">torch.Size([3, 2])</span>
<span class="sd">        &gt;&gt;&gt; _ = td_index.fill_(&#39;zeros&#39;, 1)</span>
<span class="sd">        &gt;&gt;&gt; # the indexed tensors are updated with Trues</span>
<span class="sd">        &gt;&gt;&gt; print(td.get(&#39;zeros&#39;))</span>
<span class="sd">        tensor([[[ True],</span>
<span class="sd">                 [False],</span>
<span class="sd">                 [ True],</span>
<span class="sd">                 [False]],</span>
<span class="sd">        &lt;BLANKLINE&gt;</span>
<span class="sd">                [[ True],</span>
<span class="sd">                 [False],</span>
<span class="sd">                 [ True],</span>
<span class="sd">                 [False]],</span>
<span class="sd">        &lt;BLANKLINE&gt;</span>
<span class="sd">                [[ True],</span>
<span class="sd">                 [False],</span>
<span class="sd">                 [ True],</span>
<span class="sd">                 [False]]])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_safe</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_lazy</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_inplace_set</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">TensorDictBase</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected source to be a subclass of TensorDictBase, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">source</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">_getitem_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_size does not match self.batch_size.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">_preallocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="SubTensorDict.set"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.set">[docs]</a>    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">tensor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">_run_checks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">inplace</span> <span class="ow">or</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify locked TensorDict&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Calling `SubTensorDict.set(key, value, inplace=False)` is prohibited for existing tensors. &quot;</span>
                <span class="s2">&quot;Consider calling `SubTensorDict.set_(...)` or cloning your tensordict first.&quot;</span>
            <span class="p">)</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parent_tensordict</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="n">tensor_expand</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">_expand_to_match_shape</span><span class="p">(</span>
                        <span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">_tensor</span> <span class="ow">in</span> <span class="n">tensor</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">},</span>
                <span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">_run_checks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor_expand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="o">*</span><span class="n">parent</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="o">*</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="p">:],</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_shared</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
                <span class="n">tensor_expand</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">():</span>
                <span class="n">tensor_expand</span> <span class="o">=</span> <span class="n">MemmapTensor</span><span class="p">(</span><span class="n">tensor_expand</span><span class="p">)</span>
        <span class="n">parent</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor_expand</span><span class="p">,</span> <span class="n">_run_checks</span><span class="o">=</span><span class="n">_run_checks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.keys">[docs]</a>    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KeysView</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span></div>

<div class="viewcode-block" id="SubTensorDict.set_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.set_">[docs]</a>    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">tensor</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;tensor.shape=</span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span><span class="si">}</span><span class="s2"> and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;self.batch_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> mismatch&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span>

        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_stack_onto_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">list_item</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="SubTensorDict.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">Type</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">return</span> <span class="n">dest</span><span class="p">(</span>
                <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">dest</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
            <span class="c1"># try:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dest</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_tensordict</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1"># must be device</span>
            <span class="k">return</span> <span class="n">td</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">dest</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dest must be a string, torch.device or a TensorDict &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;instance, </span><span class="si">{</span><span class="n">dest</span><span class="si">}</span><span class="s2"> not allowed&quot;</span>
            <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_orig_batch_size&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">new_size</span>

<div class="viewcode-block" id="SubTensorDict.get"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.get">[docs]</a>    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get_at</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.set_at_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.set_at_">[docs]</a>    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
        <span class="n">discard_idx_attr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">discard_idx_attr</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get_at</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
            <span class="n">tensor</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.get_at"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.get_at">[docs]</a>    <span class="k">def</span> <span class="nf">get_at</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
        <span class="n">discard_idx_attr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">discard_idx_attr</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get_at</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get_at</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="n">default</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span>
            <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="SubTensorDict.update_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.update_">[docs]</a>    <span class="k">def</span> <span class="nf">update_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_at_</span><span class="p">(</span>
            <span class="n">input_dict</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">discard_idx_attr</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clone</span><span class="o">=</span><span class="n">clone</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.update_at_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.update_at_">[docs]</a>    <span class="k">def</span> <span class="nf">update_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span>
        <span class="n">discard_idx_attr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span>
                <span class="n">key</span><span class="p">,</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">idx</span><span class="p">,</span>
                <span class="n">discard_idx_attr</span><span class="o">=</span><span class="n">discard_idx_attr</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">get_parent_tensordict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;SubTensorDict was initialized with a source of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="s2">&quot;parent tensordict not accessible&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>

<div class="viewcode-block" id="SubTensorDict.del_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.del_">[docs]</a>    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.clone"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.clone">[docs]</a>    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">recurse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">recurse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">SubTensorDict</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.is_contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.is_contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">value</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span></div>

<div class="viewcode-block" id="SubTensorDict.contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.select"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.select">[docs]</a>    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="SubTensorDict.expand"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.expand">[docs]</a>    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">idx</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">:</span>
            <span class="c1"># check that idx is not a mask, otherwise throw an error</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot expand a TensorDict masked using SubTensorDict&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="c1"># create an tuple idx with length equal to this TensorDict&#39;s number of dims</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">ndimension</span><span class="p">():</span>
            <span class="c1"># create an tuple idx with length equal to this TensorDict&#39;s number of dims</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="c1"># now that idx has the same length as the source&#39;s number of dims, we can work with it</span>

        <span class="n">source_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">num_integer_types</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">):</span>
                <span class="n">num_integer_types</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">number_of_extra_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_shape</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_integer_types</span>
        <span class="k">if</span> <span class="n">number_of_extra_dim</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">new_source_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_extra_dim</span><span class="p">)]</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">new_source_shape</span><span class="p">)</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_source_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_idx</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_source_shape</span><span class="p">))]</span>
        <span class="k">for</span> <span class="n">_idx</span><span class="p">,</span> <span class="n">_s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">source_shape</span><span class="p">):</span>
            <span class="c1"># we&#39;re iterating through the source shape and the index</span>
            <span class="c1"># we want to get the new index and the new source shape</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">_idx</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_idx</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">):</span>
                <span class="c1"># if the index is an integer, do nothing, i.e. keep the index and the shape</span>
                <span class="n">new_source_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_s</span><span class="p">)</span>
                <span class="n">new_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_idx</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">_s</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># if the source shape at this dim is 1, expand that source dim to the size that is required</span>
                <span class="n">new_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
                <span class="n">new_source_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># in this case, the source shape must be different than 1. The index is going to be identical.</span>
                <span class="n">new_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_idx</span><span class="p">)</span>
                <span class="n">new_source_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">new_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">new_source_shape</span><span class="p">)</span>
        <span class="n">new_idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">new_source</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="n">new_idx</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">_getitem_batch_size</span><span class="p">(</span><span class="n">new_source_shape</span><span class="p">,</span> <span class="n">new_idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_source</span><span class="p">[</span><span class="n">new_idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="SubTensorDict.is_shared"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.is_shared">[docs]</a>    <span class="k">def</span> <span class="nf">is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">is_shared</span><span class="p">(</span><span class="n">no_check</span><span class="o">=</span><span class="n">no_check</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.is_memmap"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.is_memmap">[docs]</a>    <span class="k">def</span> <span class="nf">is_memmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">(</span><span class="n">no_check</span><span class="o">=</span><span class="n">no_check</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.rename_key"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.rename_key">[docs]</a>    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SubTensorDict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">rename_key</span><span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">new_key</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.pin_memory"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.pin_memory">[docs]</a>    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.detach_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.detach_">[docs]</a>    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Detaching a sub-tensordict in-place cannot be done.&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.masked_fill_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.masked_fill_">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SubTensorDict.masked_fill"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.masked_fill">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_copy</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.memmap_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.memmap_">[docs]</a>    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Converting a sub-tensordict values to memmap cannot be done.&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="SubTensorDict.share_memory_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.SubTensorDict.html#torchrl.data.SubTensorDict.share_memory_">[docs]</a>    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;Casting a sub-tensordict values to shared memory cannot be done.&quot;</span>
        <span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">merge_tensordicts</span><span class="p">(</span><span class="o">*</span><span class="n">tensordicts</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;at least 2 tensordicts must be provided, got&quot;</span> <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">tensordicts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">d</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">TensorDict</span><span class="p">({},</span> <span class="p">[],</span> <span class="n">device</span><span class="o">=</span><span class="n">td</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>


<div class="viewcode-block" id="LazyStackedTensorDict"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict">[docs]</a><span class="k">class</span> <span class="nc">LazyStackedTensorDict</span><span class="p">(</span><span class="n">TensorDictBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A Lazy stack of TensorDicts.</span>

<span class="sd">    When stacking TensorDicts together, the default behaviour is to put them</span>
<span class="sd">    in a stack that is not instantiated.</span>
<span class="sd">    This allows to seamlessly work with stacks of tensordicts with operations</span>
<span class="sd">    that will affect the original tensordicts.</span>

<span class="sd">    Args:</span>
<span class="sd">         *tensordicts (TensorDict instances): a list of tensordict with</span>
<span class="sd">            same batch size.</span>
<span class="sd">         stack_dim (int): a dimension (between `-td.ndimension()` and</span>
<span class="sd">            `td.ndimension()-1` along which the stack should be performed.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; tds = [TensorDict({&#39;a&#39;: torch.randn(3, 4)}, batch_size=[3])</span>
<span class="sd">        ...     for _ in range(10)]</span>
<span class="sd">        &gt;&gt;&gt; td_stack = torch.stack(tds, -1)</span>
<span class="sd">        &gt;&gt;&gt; print(td_stack.shape)</span>
<span class="sd">        torch.Size([3, 10])</span>
<span class="sd">        &gt;&gt;&gt; print(td_stack.get(&quot;a&quot;).shape)</span>
<span class="sd">        torch.Size([3, 10, 4])</span>
<span class="sd">        &gt;&gt;&gt; print(td_stack[:, 0] is tds[0])</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_safe</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_lazy</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">tensordicts</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">stack_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># TODO: remove</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># sanity check</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">N</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;at least one tensordict must be provided to &quot;</span>
                <span class="s2">&quot;StackedTensorDict to be instantiated&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected input to be TensorDictBase instance&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">stack_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;stack_dim must be non negative, got stack_dim=</span><span class="si">{</span><span class="n">stack_dim</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">_batch_size</span> <span class="o">=</span> <span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>

        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">tensordicts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">td</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected input to be TensorDictBase instance&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>
            <span class="n">_bs</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">_device</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">device</span>
            <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="n">_device</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;devices differ, got </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_bs</span> <span class="o">!=</span> <span class="n">_batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;batch sizes in tensordicts differs, StackedTensorDict &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;cannot be created. Got td[0].batch_size=</span><span class="si">{</span><span class="n">_batch_size</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;and td[i].batch_size=</span><span class="si">{</span><span class="n">_bs</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">=</span> <span class="n">stack_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_batch_size</span><span class="p">(</span><span class="n">_batch_size</span><span class="p">,</span> <span class="n">stack_dim</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_valid_keys</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_size does not match self.batch_size.&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="c1"># devices might have changed, so we check that they&#39;re all the same</span>
        <span class="n">device_set</span> <span class="o">=</span> <span class="p">{</span><span class="n">td</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">device_set</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;found multiple devices in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">:&quot;</span> <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">device_set</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="k">return</span> <span class="n">device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

<div class="viewcode-block" id="LazyStackedTensorDict.is_shared"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.is_shared">[docs]</a>    <span class="k">def</span> <span class="nf">is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">are_shared</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">is_shared</span><span class="p">(</span><span class="n">no_check</span><span class="o">=</span><span class="n">no_check</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">are_shared</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">are_shared</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;tensordicts shared status mismatch, got </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">are_shared</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;shared tensordicts and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">are_shared</span><span class="p">)</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">are_shared</span><span class="p">)</span><span class="si">}</span><span class="s2"> non shared tensordict &quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">are_shared</span><span class="p">)</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.is_memmap"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.is_memmap">[docs]</a>    <span class="k">def</span> <span class="nf">is_memmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">are_memmap</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">is_memmap</span><span class="p">()</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;tensordicts memmap status mismatch, got </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;memmap tensordicts and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">)</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">)</span><span class="si">}</span><span class="s2"> non memmap tensordict &quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">are_memmap</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">get_valid_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_valid_keys</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span>

    <span class="k">def</span> <span class="nf">set_valid_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;setting valid keys is not permitted. valid keys are defined as &quot;</span>
            <span class="s2">&quot;the intersection of all the key sets from the TensorDicts in a &quot;</span>
            <span class="s2">&quot;stack and cannot be defined explicitely.&quot;</span>
        <span class="p">)</span>

    <span class="n">valid_keys</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_valid_keys</span><span class="p">,</span> <span class="n">set_valid_keys</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_compute_batch_size</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="n">stack_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">s</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">stack_dim</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<div class="viewcode-block" id="LazyStackedTensorDict.set"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.set">[docs]</a>    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify locked TensorDict&quot;</span><span class="p">)</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Setting tensor to tensordict failed because the shapes &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;mismatch: got tensor.shape = </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;tensordict.batch_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">proc_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">proc_tensor</span><span class="p">):</span>
            <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">_item</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span><span class="p">,</span> <span class="n">key</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.set_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.set_">[docs]</a>    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">tensor</span><span class="p">,</span>
                <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">check_shared</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                    <span class="n">tensor</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">!=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Setting tensor to tensordict failed because the shapes &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;mismatch: got tensor.shape = </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;tensordict.batch_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="s2">&quot;setting a value in-place on a stack of TensorDict is only &quot;</span>
                    <span class="s2">&quot;permitted if all members of the stack have this key in &quot;</span>
                    <span class="s2">&quot;their register.&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
            <span class="n">td</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">_item</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.set_at_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.set_at_">[docs]</a>    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">sub_td</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">sub_td</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">source</span><span class="p">,</span> <span class="n">tensordict_dest</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_item</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
                <span class="n">tensordict_dest</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># we must stack and unbind, there is no way to make it more efficient</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">list_item</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="LazyStackedTensorDict.get"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.get">[docs]</a>    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_keys</span><span class="p">):</span>
            <span class="c1"># first, let&#39;s try to update the valid keys</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_valid_keys</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_keys</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">]</span>
        <span class="n">shapes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;found more than one unique shape in the tensors to be &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;stacked (</span><span class="si">{</span><span class="n">shapes</span><span class="si">}</span><span class="s2">). This is likely due to a modification &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;of one of the stacked TensorDicts, where a key has been &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;updated/created with an uncompatible shape.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
        <span class="p">)</span>

<div class="viewcode-block" id="LazyStackedTensorDict.is_contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.is_contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.contiguous"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">source</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="c1"># we could probably just infer the items_meta by extending them</span>
            <span class="c1"># _meta_source=meta_source,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.clone"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.clone">[docs]</a>    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">recurse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">recurse</span><span class="p">:</span>
            <span class="c1"># This could be optimized using copy but we must be careful with</span>
            <span class="c1"># metadata (_is_shared etc)</span>
            <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">td</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span> <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.pin_memory"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.pin_memory">[docs]</a>    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.to"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">Type</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">})</span>
            <span class="k">return</span> <span class="n">dest</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">dest</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dest</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_tensordict</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">td</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">dest</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dest must be a string, torch.device or a TensorDict &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;instance, </span><span class="si">{</span><span class="n">dest</span><span class="si">}</span><span class="s2"> not allowed&quot;</span>
            <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_check_new_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Changing the batch_size of a LazyStackedTensorDicts can only &quot;</span>
                <span class="s2">&quot;be done with sizes that are at least as long as the &quot;</span>
                <span class="s2">&quot;stacking dimension.&quot;</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_check_new_batch_size</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_orig_batch_size&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">new_size</span>

<div class="viewcode-block" id="LazyStackedTensorDict.keys"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.keys">[docs]</a>    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_keys</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">key</span></div>

    <span class="k">def</span> <span class="nf">_update_valid_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">valid_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">valid_keys</span> <span class="o">=</span> <span class="n">valid_keys</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">valid_keys</span><span class="p">))</span>

<div class="viewcode-block" id="LazyStackedTensorDict.select"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.select">[docs]</a>    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LazyStackedTensorDict</span><span class="p">:</span>
        <span class="c1"># the following implementation keeps the hidden keys in the tensordicts</span>
        <span class="n">excluded_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_keys</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
        <span class="n">tensordicts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">td</span><span class="o">.</span><span class="n">exclude</span><span class="p">(</span><span class="o">*</span><span class="n">excluded_keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
            <span class="o">*</span><span class="n">tensordicts</span><span class="p">,</span>
            <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">item</span>
        <span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">sub_index</span>
                <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">item</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">_item</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_item</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span>
                <span class="k">for</span> <span class="n">_item</span> <span class="ow">in</span> <span class="n">item</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;setting values to a LazyStackTensorDict using boolean values is not supported yet.&quot;</span>
                <span class="s2">&quot;If this feature is needed, feel free to raise an issue on github.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># e.g. item.shape = [1, 2, 3] and stack_dim == 2</span>
            <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">items</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">_item</span><span class="p">,</span> <span class="n">sub_td</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">items</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
                    <span class="n">td</span><span class="p">[</span><span class="n">_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">sub_td</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">td</span><span class="p">,</span> <span class="n">sub_td</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
                    <span class="n">td</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="n">sub_td</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="bp">Ellipsis</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">Ellipsis</span> <span class="ow">in</span> <span class="n">item</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">convert_ellipsis_to_idx</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">_item</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">_item</span> <span class="ow">in</span> <span class="n">item</span>
        <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">),</span> <span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="n">_STR_MIXED_INDEX_ERROR</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">item</span>
        <span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">sub_index</span>
                <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">item</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_item</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_item</span> <span class="ow">in</span> <span class="n">item</span>
        <span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">Number</span><span class="p">,))</span>
            <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="n">_item</span><span class="p">]</span> <span class="k">for</span> <span class="n">_item</span> <span class="ow">in</span> <span class="n">item</span><span class="p">],</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="n">tensordict</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensordict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">slice</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="n">item</span><span class="p">],</span> <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">slice</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="n">tensordict</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensordict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="nb">slice</span><span class="p">,</span> <span class="n">Number</span><span class="p">)):</span>
            <span class="n">new_stack_dim</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Number</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">LazyStackedTensorDict</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="n">td</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">],</span>
                <span class="n">stack_dim</span><span class="o">=</span><span class="n">new_stack_dim</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">_sub_item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">_item</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_sub_item</span><span class="p">):</span>
                <span class="n">tensordicts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">[</span><span class="n">_sub_item</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">tensordicts</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensordicts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span>
            <span class="c1"># select sub tensordicts</span>
            <span class="n">_sub_item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">_item</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_sub_item</span><span class="p">):</span>
                <span class="n">tensordicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="p">[</span><span class="n">_sub_item</span><span class="p">]</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">tensordicts</span><span class="p">]</span>
            <span class="n">new_stack_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">_item</span><span class="p">,</span> <span class="n">Number</span><span class="p">)</span> <span class="k">for</span> <span class="n">_item</span> <span class="ow">in</span> <span class="n">item</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">]]</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="n">new_stack_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;selecting StackedTensorDicts with type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> is not supported yet&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="LazyStackedTensorDict.del_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.del_">[docs]</a>    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.share_memory_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.share_memory_">[docs]</a>    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.detach_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.detach_">[docs]</a>    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.memmap_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.memmap_">[docs]</a>    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">memmap_</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.expand"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.expand">[docs]</a>    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">stack_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span>
        <span class="n">new_shape_tensordicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">stack_dim</span><span class="p">]</span>
        <span class="n">tensordicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">new_shape_tensordicts</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span> <span class="o">=</span> <span class="n">tensordicts</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span> <span class="o">=</span> <span class="n">stack_dim</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensordicts</span><span class="p">,</span> <span class="n">stack_dim</span><span class="p">)</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.update"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span> <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="c1"># no op</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.update_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.update_">[docs]</a>    <span class="k">def</span> <span class="nf">update_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="c1"># no op</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.rename_key"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.rename_key">[docs]</a>    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">:</span>
            <span class="n">td</span><span class="o">.</span><span class="n">rename_key</span><span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">new_key</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="p">[</span><span class="n">key</span> <span class="k">if</span> <span class="n">key</span> <span class="o">!=</span> <span class="n">old_key</span> <span class="k">else</span> <span class="n">new_key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_valid_keys</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.masked_fill_"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.masked_fill_">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">mask_unbind</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_mask</span><span class="p">,</span> <span class="n">td</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mask_unbind</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensordicts</span><span class="p">):</span>
            <span class="n">td</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">_mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LazyStackedTensorDict.masked_fill"><a class="viewcode-back" href="../../../../reference/generated/torchrl.data.LazyStackedTensorDict.html#torchrl.data.LazyStackedTensorDict.masked_fill">[docs]</a>    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_copy</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></div></div>


<span class="k">class</span> <span class="nc">SavedTensorDict</span><span class="p">(</span><span class="n">TensorDictBase</span><span class="p">):</span>
    <span class="n">_safe</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_lazy</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected source to be a TensorDictBase instance, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">source</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">SavedTensorDict</span><span class="p">):</span>
            <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">source</span><span class="o">.</span><span class="n">values_meta</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;SavedTensorDicts is not compatible with gradients, one of Tensors has requires_grad equals True&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">file</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">()</span>  <span class="c1"># noqa: P201</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">name</span>
        <span class="c1"># if source.is_memmap():</span>
        <span class="c1">#     source = source.clone()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">source</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_size does not match self.batch_size.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensordict</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_version</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid1</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensordict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_td_fields</span> <span class="o">=</span> <span class="n">_td_fields</span><span class="p">(</span><span class="n">tensordict</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tensordict</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()}</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">tensordict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;the key &quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot; was not found in SavedTensorDict._dict_meta (keys: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s1">.&#39;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="s2">&quot;key&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_batch_size_setter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">new_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;device cannot be set using tensordict.device = device, &quot;</span>
            <span class="s2">&quot;because device cannot be updated in-place. To update device, use &quot;</span>
            <span class="s2">&quot;tensordict.to(new_device), which will return a new tensordict &quot;</span>
            <span class="s2">&quot;on the new device.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">default</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify locked TensorDict&quot;</span><span class="p">)</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">td</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">SavedTensorDict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">_stack_onto_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">list_item</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">set_at_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="c1"># no op</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict_or_td</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected value to be one of types </span><span class="si">{</span><span class="n">_accepted_classes</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">td</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">update_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_dict_or_td</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">TensorDictBase</span><span class="p">],</span>
        <span class="n">clone</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">input_dict_or_td</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">input_dict_or_td</span><span class="p">,</span> <span class="n">clone</span><span class="o">=</span><span class="n">clone</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;file&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">is_shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">is_memmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;SavedTensorDict cannot be put in shared memory.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="s2">&quot;SavedTensorDict and memmap are mutually exclusive features.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;SavedTensorDict cannot be put detached.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]]:</span>
        <span class="n">version</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_version</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">version</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_version</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The SavedTensorDict changed while querying items.&quot;</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">]:</span>
        <span class="n">version</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_version</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">version</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_version</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The SavedTensorDict changed while querying values.&quot;</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">recurse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SavedTensorDict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">_source</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="n">SavedTensorDict</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">_source</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">rename_key</span><span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">new_key</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;SavedTensorDict(</span><span class="se">\n\t</span><span class="s2">fields=</span><span class="se">{{</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_td_fields</span><span class="si">}</span><span class="se">}}</span><span class="s2">, </span><span class="se">\n\t</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;batch_size=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, </span><span class="se">\n\t</span><span class="s2">file=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">Type</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">})</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">dest</span><span class="p">(</span>
                <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">td</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="c1"># must be device</span>
            <span class="n">dest</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dest</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">dest</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_dict_meta</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">self_copy</span><span class="o">.</span><span class="n">_dict_meta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">dest</span>
            <span class="k">return</span> <span class="n">self_copy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">dest</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dest must be a string, torch.device or a TensorDict &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;instance, </span><span class="si">{</span><span class="n">dest</span><span class="si">}</span><span class="s2"> not allowed&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_tensordict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a regular TensorDict instance from the TensorDictBase.</span>
<span class="sd">            Makes a copy of the tensor dict.</span>
<span class="sd">            Memmap and shared memory tensors are converted to regular tensors.</span>
<span class="sd">        Returns:</span>
<span class="sd">            a new TensorDict object containing the same values.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">value</span><span class="o">.</span><span class="n">to_tensordict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">td</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_orig_batch_size&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">new_size</span>

    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span> <span class="o">=</span> <span class="n">td</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;pin_memory requires tensordicts that live in memory.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;file&quot;</span><span class="p">):</span>
            <span class="n">file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">file</span>
            <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">file</span> <span class="o">=</span> <span class="n">file</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">SavedTensorDict</span><span class="p">,</span> <span class="n">self_copy</span><span class="p">)</span><span class="o">.</span><span class="n">__reduce__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__reduce__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_index</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">sub_index</span>
                <span class="k">for</span> <span class="n">sub_index</span> <span class="ow">in</span> <span class="n">idx</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="ow">is</span> <span class="bp">Ellipsis</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">Ellipsis</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">convert_ellipsis_to_idx</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">_idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">_idx</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="n">_STR_MIXED_INDEX_ERROR</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_idx</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_idx</span> <span class="ow">in</span> <span class="n">idx</span>
        <span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">out</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">,)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">idx</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                <span class="s2">&quot;indexing a tensordict with td.batch_dims==0 is not permitted&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sub_tensordict</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="n">td</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">td</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_copy</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_CustomOpTensorDict</span><span class="p">(</span><span class="n">TensorDictBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Encodes lazy operations on tensors contained in a TensorDict.&quot;&quot;&quot;</span>

    <span class="n">_lazy</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">,</span>
        <span class="n">custom_op</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">inv_op</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">custom_op_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inv_op_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Expected source to be a TensorDictBase isntance, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">source</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_op</span> <span class="o">=</span> <span class="n">custom_op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span> <span class="o">=</span> <span class="n">inv_op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span> <span class="o">=</span> <span class="n">custom_op_kwargs</span> <span class="k">if</span> <span class="n">custom_op_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span> <span class="o">=</span> <span class="n">inv_op_kwargs</span> <span class="k">if</span> <span class="n">inv_op_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;batch_size does not match self.batch_size.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_custom_op_kwargs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">source_meta_tensor</span><span class="p">:</span> <span class="n">MetaTensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Allows for a transformation to be customized for a certain shape,</span>
<span class="sd">        device or dtype. By default, this is a no-op on self.custom_op_kwargs</span>

<span class="sd">        Args:</span>
<span class="sd">            source_meta_tensor: corresponding MetaTensor</span>

<span class="sd">        Returns:</span>
<span class="sd">            a dictionary with the kwargs of the operation to execute</span>
<span class="sd">            for the tensor</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span>

    <span class="k">def</span> <span class="nf">_update_inv_op_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Allows for an inverse transformation to be customized for a</span>
<span class="sd">        certain shape, device or dtype.</span>

<span class="sd">        By default, this is a no-op on self.inv_op_kwargs</span>

<span class="sd">        Args:</span>
<span class="sd">            source_tensor: corresponding tensor</span>

<span class="sd">        Returns:</span>
<span class="sd">            a dictionary with the kwargs of the operation to execute for</span>
<span class="sd">            the tensor</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">DEVICE_TYPING</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">_make_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op</span><span class="p">)(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_custom_op_kwargs</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_get_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetaTensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="n">MetaTensor</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op</span>
            <span class="p">)(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size_setter</span><span class="p">(</span><span class="n">new_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_orig_batch_size&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span> <span class="o">==</span> <span class="n">new_size</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_orig_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">new_size</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;_no_default_&quot;</span><span class="p">,</span>
        <span class="n">_return_original_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">source_meta_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_get_meta</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">transformed_tensor</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op</span><span class="p">)(</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_custom_op_kwargs</span><span class="p">(</span><span class="n">source_meta_tensor</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">_return_original_tensor</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">transformed_tensor</span>
            <span class="k">return</span> <span class="n">transformed_tensor</span><span class="p">,</span> <span class="n">item</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_return_original_tensor</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;_return_original_tensor not compatible with get(..., &quot;</span>
                    <span class="s2">&quot;default=smth)&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support setting values. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Consider calling .contiguous() before calling this method.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify locked TensorDict&quot;</span><span class="p">)</span>
        <span class="n">proc_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">proc_value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">proc_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span><span class="p">)(</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_inv_op_kwargs</span><span class="p">(</span><span class="n">proc_value</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">proc_value</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">no_check</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_CustomOpTensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">no_check</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not support setting values. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Consider calling .contiguous() before calling this method.&quot;</span>
                <span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span><span class="p">)(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_inv_op_kwargs</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_at_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">COMPATIBLE_TYPES</span><span class="p">],</span> <span class="n">idx</span><span class="p">:</span> <span class="n">INDEX_TYPING</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_CustomOpTensorDict</span><span class="p">:</span>
        <span class="n">transformed_tensor</span><span class="p">,</span> <span class="n">original_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">_return_original_tensor</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">transformed_tensor</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">()</span> <span class="o">!=</span> <span class="n">original_tensor</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> original tensor and transformed_in do not point to the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;same storage. Setting values in place is not currently &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;supported in this setting, consider calling &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`td.clone()` before `td.set_at_(...)`&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">_accepted_classes</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_input</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span> <span class="n">check_tensor_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_device</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="n">transformed_tensor</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;stacking tensordicts is not allowed for type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;consider calling &#39;to_tensordict()` first&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">custom_op_kwargs_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="p">)</span>
        <span class="n">indented_source</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">indent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;source=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="n">indented_source</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2">op=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">custom_op_kwargs_str</span><span class="si">}</span><span class="s2">))&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KeysView</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">keys</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_CustomOpTensorDict</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">self_copy</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">self_copy</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self_copy</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">recurse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">recurse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">value</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">TensorDict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">rename_key</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">old_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_CustomOpTensorDict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">rename_key</span><span class="p">(</span><span class="n">old_key</span><span class="p">,</span> <span class="n">new_key</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">del_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_CustomOpTensorDict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">del_</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">,</span> <span class="n">Type</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dest</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="k">return</span> <span class="n">dest</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
            <span class="n">td</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">self_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">self_copy</span><span class="o">.</span><span class="n">_source</span> <span class="o">=</span> <span class="n">td</span>
            <span class="k">return</span> <span class="n">self_copy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dest must be a string, torch.device or a TensorDict &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;instance, </span><span class="si">{</span><span class="n">dest</span><span class="si">}</span><span class="s2"> not allowed&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">pin_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">detach_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">masked_fill_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># source_meta_tensor = self._get_meta(key)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">mask_exp</span> <span class="o">=</span> <span class="n">expand_right</span><span class="p">(</span>
                <span class="n">mask</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_dims</span> <span class="p">:])</span>
            <span class="p">)</span>
            <span class="n">mask_proc_inv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mask_exp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op</span><span class="p">)(</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_inv_op_kwargs</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">val</span><span class="p">[</span><span class="n">mask_proc_inv</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">td_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">td_copy</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">memmap_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">memmap_</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_memmap</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">share_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lock</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_shared</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_locked</span> <span class="o">=</span> <span class="n">lock</span>


<span class="k">class</span> <span class="nc">UnsqueezedTensorDict</span><span class="p">(</span><span class="n">_CustomOpTensorDict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A lazy view on an unsqueezed TensorDict.</span>

<span class="sd">    When calling `tensordict.unsqueeze(dim)`, a lazy view of this operation is</span>
<span class="sd">    returned such that the following code snippet works without raising an</span>
<span class="sd">    exception:</span>

<span class="sd">        &gt;&gt;&gt; assert tensordict.unsqueeze(dim).squeeze(dim) is tensordict</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;a&#39;: torch.randn(3, 4)}, batch_size=[3])</span>
<span class="sd">        &gt;&gt;&gt; td_unsqueeze = td.unsqueeze(-1)</span>
<span class="sd">        &gt;&gt;&gt; print(td_unsqueeze.shape)</span>
<span class="sd">        torch.Size([3, 1])</span>
<span class="sd">        &gt;&gt;&gt; print(td_unsqueeze.squeeze(-1) is td)</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dim&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">unsqueezed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">[</span><span class="s2">&quot;dim&quot;</span><span class="p">]</span>
        <span class="n">diff_to_apply</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">unsqueezed_dim</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">list_item_unsqueeze</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">item</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">unsqueezed_dim</span> <span class="o">-</span> <span class="n">diff_to_apply</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">list_item</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_stack_onto_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">list_item_unsqueeze</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SqueezedTensorDict</span><span class="p">(</span><span class="n">_CustomOpTensorDict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A lazy view on a squeezed TensorDict.</span>
<span class="sd">    See the `UnsqueezedTensorDict` class documentation for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">inv_op_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dim&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inv_op_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">inv_op_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="n">inv_op_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="n">inv_op_dim</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="n">squeezed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">[</span><span class="s2">&quot;dim&quot;</span><span class="p">]</span>
        <span class="c1"># dim=0, squeezed_dim=2, [3, 4, 5] [3, 4, 1, 5] [[4, 5], [4, 5], [4, 5]] =&gt; unsq 1</span>
        <span class="c1"># dim=1, squeezed_dim=2, [3, 4, 5] [3, 4, 1, 5] [[3, 5], [3, 5], [3, 5], [3, 4]] =&gt; unsq 1</span>
        <span class="c1"># dim=2, squeezed_dim=2, [3, 4, 5] [3, 4, 1, 5] [[3, 4], [3, 4], ...] =&gt; unsq 2</span>
        <span class="n">diff_to_apply</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="n">squeezed_dim</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">list_item_unsqueeze</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">item</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">squeezed_dim</span> <span class="o">-</span> <span class="n">diff_to_apply</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">list_item</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_stack_onto_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">list_item_unsqueeze</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ViewedTensorDict</span><span class="p">(</span><span class="n">_CustomOpTensorDict</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_update_custom_op_kwargs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">source_meta_tensor</span><span class="p">:</span> <span class="n">MetaTensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">new_dim_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">))</span>
        <span class="n">new_dim_list</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">source_meta_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_dims</span> <span class="p">:])</span>
        <span class="n">new_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">new_dim_list</span><span class="p">)</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">)</span>
        <span class="n">new_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="n">new_dim</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">new_dict</span>

    <span class="k">def</span> <span class="nf">_update_inv_op_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">))</span>
        <span class="n">size</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="p">:])</span>
        <span class="n">new_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="n">new_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span><span class="p">)</span>
        <span class="n">new_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="n">new_dim</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">new_dict</span>

    <span class="k">def</span> <span class="nf">view</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">infer_size_impl</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PermutedTensorDict</span><span class="p">(</span><span class="n">_CustomOpTensorDict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A lazy view on a TensorDict with the batch dimensions permuted.</span>

<span class="sd">    When calling `tensordict.permute(dims_list, dim)`, a lazy view of this operation is</span>
<span class="sd">    returned such that the following code snippet works without raising an</span>
<span class="sd">    exception:</span>

<span class="sd">        &gt;&gt;&gt; assert tensordict.permute(dims_list, dim).permute(dims_list, dim) is tensordict</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from torchrl.data import TensorDict</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; td = TensorDict({&#39;a&#39;: torch.randn(4, 5, 6, 9)}, batch_size=[3])</span>
<span class="sd">        &gt;&gt;&gt; td_permute = td.permute(dims=(2, 1, 0))</span>
<span class="sd">        &gt;&gt;&gt; print(td_permute.shape)</span>
<span class="sd">        torch.Size([6, 5, 4])</span>
<span class="sd">        &gt;&gt;&gt; print(td_permute.permute(dims=(2, 1, 0)) is td)</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">permute</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">dims_list</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dims_list</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">dims_list</span> <span class="o">=</span> <span class="n">dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;number of dims don&#39;t match in permute (got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">dims_list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">dims_list</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dims_list</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_op_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dims&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_source</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">dims_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_missing_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">dim_diff</span> <span class="o">=</span> <span class="n">num_dims</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span>
        <span class="n">all_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">dim_diff</span>
            <span class="n">all_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">all_dims</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_custom_op_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_meta_tensor</span><span class="p">:</span> <span class="n">MetaTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">new_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_missing_dims</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">source_meta_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">[</span><span class="s2">&quot;dims&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;dims&quot;</span><span class="p">:</span> <span class="n">new_dims</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">kwargs</span>

    <span class="k">def</span> <span class="nf">_update_inv_op_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">new_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_missing_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="p">:]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">[</span><span class="s2">&quot;dims&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;dims&quot;</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">new_dims</span><span class="p">))})</span>
        <span class="k">return</span> <span class="n">kwargs</span>

    <span class="k">def</span> <span class="nf">_stack_onto_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">list_item</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">COMPATIBLE_TYPES</span><span class="p">],</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDictBase</span><span class="p">:</span>

        <span class="n">permute_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_op_kwargs</span><span class="p">[</span><span class="s2">&quot;dims&quot;</span><span class="p">]</span>
        <span class="n">inv_permute_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">permute_dims</span><span class="p">)</span>
        <span class="n">new_dim</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inv_permute_dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="o">==</span> <span class="n">dim</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">inv_permute_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">inv_permute_dims</span> <span class="k">if</span> <span class="n">p</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">]</span>
        <span class="n">inv_permute_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">inv_permute_dims</span><span class="p">))</span>

        <span class="n">list_permuted_items</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">list_item</span><span class="p">:</span>
            <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inv_permute_dims</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">item</span><span class="o">.</span><span class="n">ndimension</span><span class="p">())</span>
            <span class="p">)</span>
            <span class="n">list_permuted_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">perm</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_source</span><span class="o">.</span><span class="n">_stack_onto_</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">list_permuted_items</span><span class="p">,</span> <span class="n">new_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>


<span class="k">def</span> <span class="nf">_td_fields</span><span class="p">(</span><span class="n">td</span><span class="p">:</span> <span class="n">TensorDictBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">indent</span><span class="p">(</span>
        <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="nb">sorted</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">get_repr</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">td</span><span class="o">.</span><span class="n">items_meta</span><span class="p">()])</span>
        <span class="p">),</span>
        <span class="mi">4</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_keys</span><span class="p">(</span>
    <span class="n">list_of_tensordicts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">keys</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="n">list_of_tensordicts</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">):</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">strict</span><span class="p">:</span>
                <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">keys</span><span class="p">))</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">keys</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;got keys </span><span class="si">{</span><span class="n">keys</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> which are &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;incompatible&quot;</span>
                    <span class="p">)</span>
    <span class="k">return</span> <span class="n">keys</span>


<span class="n">_accepted_classes</span> <span class="o">=</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">MemmapTensor</span><span class="p">,</span> <span class="n">TensorDictBase</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_expand_to_match_shape</span><span class="p">(</span><span class="n">parent_batch_size</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">self_batch_dims</span><span class="p">,</span> <span class="n">self_device</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="o">*</span><span class="n">parent_batch_size</span><span class="p">,</span>
            <span class="o">*</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">self_batch_dims</span><span class="p">:],</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">self_device</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># tensordict</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
            <span class="p">{},</span>
            <span class="p">[</span><span class="o">*</span><span class="n">parent_batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">self_batch_dims</span><span class="p">:]],</span>
            <span class="n">device</span><span class="o">=</span><span class="n">self_device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="c1"># seems like we can do without registering in pytree -- which requires us to create a new TensorDict,</span>
<span class="c1"># an operation that does not come for free</span>

<span class="c1"># def _flatten_tensordict(tensordict):</span>
<span class="c1">#     return tensordict, tuple()</span>
<span class="c1">#     # keys, values = list(zip(*tensordict.items()))</span>
<span class="c1">#     # # represent values as batched tensors</span>
<span class="c1">#     # vmap_level = 0</span>
<span class="c1">#     # in_dim</span>
<span class="c1">#     # values = [_add_batch_dim(value, in_dim, vmap_level)</span>
<span class="c1">#     # return list(values), (list(keys), tensordict.device, tensordict.batch_size)</span>
<span class="c1">#</span>
<span class="c1"># def _unflatten_tensordict(values, context):</span>
<span class="c1">#     return values</span>
<span class="c1">#     # values = [_unwrap_value(value) for value in values]</span>
<span class="c1">#     # keys, device, batch_size = context</span>
<span class="c1">#     # print(values[0].shape)</span>
<span class="c1">#     # return TensorDict(</span>
<span class="c1">#     #     {key: value for key, value in zip(keys, values)},</span>
<span class="c1">#     #     [],</span>
<span class="c1">#     #     # [*new_batch_sizes[0], *batch_size],</span>
<span class="c1">#     #     # new_batch_sizes[0],</span>
<span class="c1">#     #     device=device</span>
<span class="c1">#     # )</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># _register_pytree_node(TensorDict, _flatten_tensordict, _unflatten_tensordict)</span>


<span class="k">def</span> <span class="nf">make_tensordict</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DEVICE_TYPING</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>  <span class="c1"># source</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorDict</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a TensorDict created from the keyword arguments.</span>

<span class="sd">    If batch_size is not specified, returns the maximum batch size possible</span>

<span class="sd">    Args:</span>
<span class="sd">        **kwargs (TensorDict or torch.Tensor): keyword arguments as data source.</span>
<span class="sd">        batch_size (iterable of int, optional): a batch size for the tensordict.</span>
<span class="sd">        device (torch.device or compatible type, optional): a device for the TensorDict.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_find_max_batch_size</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TensorDict</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_find_max_batch_size</span><span class="p">(</span><span class="n">source</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorDictBase</span><span class="p">,</span> <span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="n">tensor_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tensor_data</span><span class="p">:</span>  <span class="c1"># when source is empty</span>
        <span class="k">return</span> <span class="n">batch_size</span>
    <span class="n">curr_dim</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tensor_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">curr_dim</span><span class="p">:</span>
            <span class="n">curr_dim_size</span> <span class="o">=</span> <span class="n">tensor_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">curr_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">batch_size</span>
        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">curr_dim</span> <span class="ow">or</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">curr_dim</span><span class="p">)</span> <span class="o">!=</span> <span class="n">curr_dim_size</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">batch_size</span>
        <span class="n">batch_size</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_dim_size</span><span class="p">)</span>
        <span class="n">curr_dim</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>